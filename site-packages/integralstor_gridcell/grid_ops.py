"""Operations pertaining to setting up the grid - initial setup, salt, DNS, CTDB, etc..

This exports:
  _regenerate_manifest_and_status - Regenerates the manifest and status files.
  get_accepted_minions - Gets the list of accepted salt minions.
  get_pending_minions - Gets the list of pending salt minions.
  restart_minions - Restart the specified minions.
  accept_salt_key - Accepts the salt key of the specified gridcell.
  delete_salt_key - Deletes the salt key for the specified gridcell.
  sync_salt_modules - Sync all salt modules with the specified minions.
  get_minion_ip - Gets the bond0 IP of the specified salt minion.
  place_ctdb_files - Copy CTDB files from the admin vol lock directory to their respective localhost path.
  unplace_ctdb_files - Removes CTDB files from their respective localhost path.
  copy_appropriate_rc_local - Depending on whether primary/secondary or normal, it copies the appropriate rc.local files.
  start_or_stop_services - Starts or stops the set of services on the specified gridcells.
  chkconfig_services - Ensures that a set of services start at boot on the specified gridcells.
  mount_admin_volume - Mounts the admin volume on the specified gridcells.
  unmount_admin_volume - Unmounts the admin volume on the specified gridcells.
  set_pool_status - Either touches or removes a file to denote if the gridcell is part of the pool or not.
  add_a_gridcell_to_storage_pool - Performs a set of operations using other grid_ops functions to get a gridcell into the storage pool.
  revert_add_a_gridcell_to_storage_pool - Reverts the process of getting a gridcell into the storage pool.
  remove_a_gridcell_from_storage_pool - Performs a bunch of operations using other gridops functions to remove a gridcell from the storage pool.
  revert_remove_a_gridcell_from_storage_pool - Performs a bunch of operations using other gridops functions to revert the removal of a gridcell from the storage pool.
  add_gridcells_to_grid - Performa a bunch of operations to add a set of gridcells to the grid..
  get_all_salt_keys - In order to reduce code duplication, this function returns all salt keys for other functions to use
  is_active_admin_gridcell - Scrolls down the list of admin gridcells and tells us if the calling gridcell is the active one that needs to run the scripts

"""
import salt.client, salt.wheel

import socket, time, os

from integralstor_common import command, audit, common, networking
from integralstor_gridcell import ctdb, gluster_trusted_pools, dns, xml_parse

def _regenerate_manifest_and_status(first_time = False):
  """(Re)generates the manifest and status file.

  Return True if successful and False if not.

  first_time - Tells us if this is being called from the first time setup when we need to store a tmp path to store the files. Else in the integralview admin vol's config dir.
  """

  rc = -1
  try:
    if first_time:
      ss_path, err = common.get_tmp_path()
      if err:
        raise Exception(err)
    else:
      ss_path, err = common.get_system_status_path()
      if err:
        raise Exception(err)

    #Path to the gridcell scripts
    scripts_path, err = common.get_python_scripts_path()
    if err:
      raise Exception(err)

    #Path to the common scripts
    common_python_scripts_path, err = common.get_common_python_scripts_path()
    if err:
      raise Exception(err)

    ret, err = command.get_command_output("python %s/generate_manifest.py %s"%(common_python_scripts_path, ss_path))
    #print ret, err
    if err:
      raise Exception(err)

    ret, err = command.get_command_output("python %s/generate_status.py %s"%(common_python_scripts_path, ss_path))
    #print ret, err
    if err:
      raise Exception(err)

  except Exception, e:
    return False, 'Error regenerating the new configuration : %s'%str(e)
  else:
    return True, None

def salt_ping_all():
  status = None
  try:
    client = salt.client.LocalClient()
    status = client.cmd('*', 'test.ping')
  except Exception, e:
    return None, "Error pinging admin agents : %s"%str(e)
  else:
    return status, None

def get_salt_wheel():
  """In order to reduce code duplication, this function returns the salt wheel for other functions to use"""
  wheel = None
  try :
    #Get the location of the salt master config file.
    cfg, err = common.get_salt_master_config()
    if err:
      raise Exception(err)

    opts = salt.config.master_config(cfg)
    wheel = salt.wheel.Wheel(opts)
  except Exception, e:
    return None, "Error retrieving salt wheel : %s"%str(e)
  else:
    return wheel, None

def get_all_salt_keys(wheel = None):
  """In order to reduce code duplication, this function returns all salt keys for other functions to use"""
  keys = None
  try :
    if not wheel:
      wheel, err = get_salt_wheel()
      if err:
        raise Exception(err)

    keys = wheel.call_func('key.list_all')
  except Exception, e:
    return None, "Error retrieving all salt keys : %s"%str(e)
  else:
    return keys, None

def get_accepted_minions():
  """Get the list of accepted salt minions."""

  minion_list = []
  try :

    keys, err = get_all_salt_keys()
    if err:
      raise Exception(err)
    if keys:
      minion_list = keys['minions']

  except Exception, e:
    return None, "Error retrieving accepted minions : %s"%str(e)
  else:
    return minion_list, None


def get_pending_minions():
  """Get the list of pending salt minions."""
  pending_minions = None
  try:
    keys, err = get_all_salt_keys()
    if err:
      raise Exception(err)
    if keys:
      pending_minions = keys['minions_pre']
  except Exception, e:
    return None, 'Error retrieving pending minions : %s'%str(e)
  else:
    return pending_minions, None

def restart_minions(client, minion_list):
  """Restart the salt minion in the specified nodes.

  client - The salt client handle
  minion_list - The list of nodes on which this is to be done.
  """

  try:
    r1 = client.cmd(minion_list, 'cmd.run', ['echo service salt-minion restart | at now + 1 minute'], expr_form='list')
  except Exception, e:
    return False, 'Error restarting minions : %s'%str(e)
  else:
    return True, None

def accept_salt_key(wheel, m):
  """Accept the specified host into salt..

  wheel - salt's wheel handle.
  m - the host to accept.
  """
  ret = -1
  try:
    if not m:
      raise Exception('Required parameters not passed')
    if not wheel:
      wheel, err = get_salt_wheel()
      if err:
        raise Exception(err)

    if not wheel.call_func('key.accept', match=('%s'%m)):
      raise Exception('GRIDCell %s'%m)
    else:
      ret = 0
  except Exception, e:
    return False, 'Error accepting GRIDCell key : %s'%str(e)
  else:
    return True, None

def accept_salt_keys(wheel, hosts, print_progress = False):
  """Accept the specified hosts into salt..

  wheel - salt's wheel handle.
  hosts - the hosts to accept.
  """
  ret = {}
  try:
    if not hosts:
      raise Exception('Required parameters not passed')
    if not wheel:
      wheel, err = get_salt_wheel()
      if err:
        raise Exception(err)
    ret = wheel.call_func('key.accept', match=(','.join(hosts)))
    if not ret or 'minions' not in ret:
      raise Exception('Error accepting GRIDCells')
    failed_gridcells = []
    accepted_gridcells = []
    for host in hosts:
      if host not in ret['minions']:
        failed_gridcells.append(host)
      else:
        accepted_gridcells.append(host)
    ret['accepted_gridcells'] = accepted_gridcells
    ret['failed_gridcells'] = failed_gridcells
  except Exception, e:
    return None, 'Error accepting GRIDCell keys : %s'%str(e)
  else:
    return ret, None

def delete_salt_key(hostname):
  """Delete the salt minion key of the specified hostname this excommunicating it from the salt master's purview.

  hostname - the host to accept.
  """

  try:

    wheel, err = get_salt_wheel()
    if err:
      raise Exception(err)

    keys, err = get_all_salt_keys(wheel)
    if err:
      raise Exception(err)

    #First check if it is currently part of the master's keys.
    if (not keys) or ('minions' not in keys) or (hostname not in keys['minions']):
      raise Exception("Specified GRIDCell is not part of the grid")

    wheel.call_func('key.delete', match=(hostname))

    #The host continues to respond to requests even after the delete. Sigh! So need to loop until it stops..
    client = salt.client.LocalClient()
    r1 = client.cmd('*', 'test.ping')
    count = 1
    while count <= 100:
      print 'count - ', count
      print r1
      if not r1 or hostname not in r1.keys():
        print 'ok after %d retries'%count
        break
      count = count + 1
      time.sleep(1)
      r1 = client.cmd('*', 'test.ping')

  except Exception, e:
    errors = "Error removing GRIDCell key from the grid : %s"%str(e)
    return False, errors
  else:
    return True, None

def delete_all_salt_keys():
  """Delete all the accepted salt minion keys thus excommunicating them from the salt master's purview.

  """
  try:
    minions, err = get_accepted_minions()
    if err:
      raise Exception("Error retrieving accepted minion list")
    if minions:
      for minion in minions:
        print "Disconnecting GRIDCell %s"%minion
        rc, err = delete_salt_key(minion)
        if not rc:
          if err:
            raise Exception(err)
          else:
            raise Exception ("Error deleting salt key : Unknown error occurred")
  except Exception, e:
    errors = "Error removing all GRIDCell keys from the grid : %s"%str(e)
    return False, errors
  else:
    return True, None

def sync_salt_modules(client, minion_list):
  """Sync the salt modules onto the specified minions.

  client - the salt client handle.
  minion_list - the list of hostnames onto which the modules need to be synced.
  """

  try:
    rc = client.cmd(minion_list, 'saltutil.sync_modules', expr_form='list')
  except Exception, e:
    return False, 'Error syncing salt modules : %s'%str(e)
  else:
    return True, None

def check_salt_connectivity(client, hostname_list):
  """Check the salt connectivity to the minions in hostname_list

  Returns a True or False for each host in hostname_list

  client - salt's client handle.
  hostname_list - The list of nodes on which to perform this operation.
  """
  return_dict = {}
  try :

    if not client:
      client = salt.client.LocalClient()

    r1 = client.cmd(hostname_list, 'test.ping', expr_form='list')
    #print r1
    if r1:
      for node, ret in r1.items():
        #print ret
        return_dict[node] = ret
    else:
      raise Exception('No response from GRIDCells')
  except Exception, e:
    return None, 'Error checking salt connectivity : %s'%str(e)
  else:
    return return_dict, None

def get_minion_ip(client, m):
  """Get the IP address assigned to the bond0 interface for the specified host.

  client - the salt client handle.
  m - the hostname for which the IP address is desired.
  """
  ip = None
  try:
    r = client.cmd(m, 'grains.item', ['ip_interfaces'])
    print r
    if r:
      if 'ip_interfaces' in r[m] and r[m]['ip_interfaces']['bond0']:
        ip = r[m]['ip_interfaces']['bond0'][0]
      else:
        raise Exception("The IP address for bond0 in GRIDCell %s does not seem to have been configured."%m)
    else:
      raise Exception("Could not retrieve the IP for GRIDCell %s."%m)
  except Exception, e:
    return None, 'Error retrieving minion IP address : %s'%e
  else:
    return ip, None

def get_minion_ips(client, hostname_list):
  """Get the IP address assigned to the bond0 interface for a list of hosts.

  client - the salt client handle.
  hostname_list - the hostnames for which the IP address is desired.
  """
  mapping_dict = {}
  try:
    r = client.cmd(hostname_list, 'grains.item', ['ip_interfaces'], expr_form = 'list')
    #print r
    if r:
      for hostname, interface_info in r.items():
        if 'ip_interfaces' in interface_info and interface_info['ip_interfaces']['bond0']:
          ip = interface_info['ip_interfaces']['bond0'][0]
          mapping_dict[hostname] = ip
        else:
          raise Exception("The IP address for bond0 in GRIDCell %s does not seem to have been configured."%hostname)
    else:
      raise Exception("Could not retrieve the IP for GRIDCells.")
  except Exception, e:
    return None, 'Error retrieving minion IP addresses : %s'%e
  else:
    return mapping_dict, None

def check_network_connectivity(hostname_list):
  """Check the network connectivity to the GRIDCells in hostname_list

  Returns a True or False for each host in hostname_list

  hostname_list - The list of nodes on which to perform this operation.
  """
  return_dict = {}
  try :
    for host in hostname_list:
      (ret, rc), err = command.execute_with_rc('ping -c 1 %s'%host)
      if err:
        return_dict[host] = 'err'
      elif rc == 0:
        return_dict[host] = True
      else:
        return_dict[host] = False

  except Exception, e:
    return None, 'Error checking network connectivity : %s'%str(e)
  else:
    return return_dict, None

def link_kerberos_file(client, hostname_list):
  """Soft link the default Kerberos krb5.conf config file to files in the integralview admin vol so the kinit can work on those nodes. This operation is performed on the specified set of nodes.

  client - salt's client handle.
  hostname_list - The list of nodes on which to perform this operation.
  """
  try :
    #Get the admin vol's config dir.
    config_dir, err = common.get_config_dir()
    if err:
      raise Exception(err)

    #print "Removing original krb5.conf file on GRIDCell %s."%','.join(hostname_list)
    r1 = client.cmd(hostname_list, 'cmd.run_all', ['rm -f /etc/krb5.conf'], expr_form='list')
    #print "Removed original krb5.conf file on GRIDCell %s."%','.join(hostname_list)

    #print "Linking the krb5.conf file on GRIDCell %s."%','.join(hostname_list)
    r1 = client.cmd(hostname_list, 'cmd.run_all', ['ln -s %s/lock/krb5.conf /etc/krb5.conf'%config_dir], expr_form='list')
    if r1:
      for node, ret in r1.items():
        #print ret
        if ret["retcode"] != 0:
          errors = 'Error linking kerberos config file on GRIDCell %s'%node
          raise Exception(errors)
    #print "Linked the krb5.conf file on GRIDCell %s."%','.join(hostname_list)

  except Exception, e:
    error_str = str(e)
    return False, error_str
  else:
    return True, None

def place_ctdb_files(client, hostname_list):
  """Copy CTDB ctdb, nodes and public_addresses config files from files in the integralstor admin vol to their respective localhost locations. They will be made consistent across all nodes later through cron-run-scripts. This operation is performed on the specified set of nodes.

  client - salt's client handle.
  hostname_list - The list of nodes on which to perform this operation.
  """
  try :
    #Get the admin vol's config dir.
    config_dir, err = common.get_config_dir()
    if err:
      raise Exception(err)

    #print "Removing original CTDB config file on GRIDCell %s."%','.join(hostname_list)
    r1 = client.cmd(hostname_list, 'cmd.run_all', ['rm -f /etc/sysconfig/ctdb'], expr_form='list')
    #print "Removed original CTDB config file on GRIDCell %s."%','.join(hostname_list)

    #print "Placing the CTDB config file on GRIDCell %s."%','.join(hostname_list)
    r1 = client.cmd(hostname_list, 'cmd.run_all', ['cp %s/lock/ctdb /etc/sysconfig/ctdb'%config_dir], expr_form='list')
    if r1:
      for node, ret in r1.items():
        #print ret
        if ret["retcode"] != 0:
          errors = 'Error placing ctdb config file on GRIDCell %s'%node
          raise Exception(errors)
    #print "Placed the CTDB config file on GRIDCell %s."%','.join(hostname_list)

    #print "Removing original CTDB nodes file on GRIDCell %s."%','.join(hostname_list)
    r1 = client.cmd(hostname_list, 'cmd.run_all', ['rm -f /etc/ctdb/nodes'], expr_form='list')
    #print "Removed original CTDB nodes file on GRIDCell %s."%','.join(hostname_list)

    #print "Placing the CTDB nodes file on GRIDCell %s."%','.join(hostname_list)
    r1 = client.cmd(hostname_list, 'cmd.run_all', ['cp %s/lock/nodes /etc/ctdb/nodes'%config_dir], expr_form='list')
    if r1:
      for node, ret in r1.items():
        #print ret
        if ret["retcode"] != 0:
          errors = "Error plcaing the CTDB nodes file on GRIDCell %s"%node
          #Undo the previous linking
          r1 = client.cmd(hostname_list, 'cmd.run_all', ['rm -f /etc/sysconfig/ctdb'], expr_form='list')
          raise Exception(errors)

    #print "Removing original CTDB public_addresses file on GRIDCell %s."%','.join(hostname_list)
    r1 = client.cmd(hostname_list, 'cmd.run_all', ['rm -f /etc/ctdb/public_addresses'], expr_form='list')
    #print "Removed original CTDB public_addresses file on GRIDCell %s."%','.join(hostname_list)

    #print "Placing the CTDB public_addresses file on GRIDCell %s."%','.join(hostname_list)
    r1 = client.cmd(hostname_list, 'cmd.run_all', ['cp %s/lock/public_addresses /etc/ctdb/public_addresses'%config_dir], expr_form='list')
    if r1:
      for node, ret in r1.items():
        #print ret
        if ret["retcode"] != 0:
          errors = "Error placing the CTDB nodes file on GRIDCell %s"%node
          #Undo the previous linking
          r1 = client.cmd(hostname_list, 'cmd.run_all', ['rm -f /etc/sysconfig/ctdb'], expr_form='list')
          raise Exception(errors)

  except Exception, e:
    error_str = str(e)
    return False, error_str
  else:
    return True, None

def unplace_ctdb_files(client, hostname_list):
  """Remove CTDB ctdb, nodes and public_addresses config files from. This operation is performed on the specified set of nodes.

  client - salt's client handle.
  hostname_list - The list of nodes on which to perform this operation.
  """
  try :
    r1 = client.cmd(hostname_list, 'cmd.run_all', ['rm -f /etc/sysconfig/ctdb'], expr_form='list')
    r1 = client.cmd(hostname_list, 'cmd.run_all', ['rm -f /etc/ctdb/nodes'], expr_form='list')
    r1 = client.cmd(hostname_list, 'cmd.run_all', ['rm -f /etc/ctdb/public_addresses'], expr_form='list')
  except Exception, e:
    err = "Error removing CTDB files : %s"%str(e)
    return False, err
  else:
    return True, None

def copy_appropriate_rc_local(client, hostname_list, action):
  try :
    defaults_dir, err = common.get_defaults_dir()
    if err:
      raise Exception(err)
    if not action:
      raise Exception('No action specified')
    if action not in ['add_to_grid', 'remove_from_grid']:
      raise Exception('Invalied action specified')
    if action == 'add_to_grid':
      cmd = 'cp %s/rc_local/normal/rc.local.in_cluster /etc/rc.local'%defaults_dir
    else:
      cmd = 'cp %s/rc_local/normal/rc.local.not_in_cluster /etc/rc.local'%defaults_dir
    #print cmd
    r1 = client.cmd(hostname_list, 'cmd.run_all', [cmd], expr_form='list')
    #print r1
    if r1:
      for node, ret in r1.items():
        #print ret
        if ret["retcode"] != 0:
          errors = "Error copying on GRIDCell %s"%node
          raise Exception(errors)
    cmd = 'chmod 755 /etc/rc.local'
    r1 = client.cmd(hostname_list, 'cmd.run_all', [cmd], expr_form='list')
    #print r1
    if r1:
      for node, ret in r1.items():
        #print ret
        if ret["retcode"] != 0:
          errors = "Error changing permissions on GRIDCell %s"%node
          raise Exception(errors)
  except Exception, e:
    return False, 'Error placing rc.local : %s'%str(e)
  else:
    return True, None

def start_or_stop_services(client, hostname_list, action):
  """Start or stop ctdb and winbind services in the specified nodes.

  client - salt's client handle.
  hostname_list - The list of nodes on which to perform this operation.
  action - either 'start' or 'stop'.
  """
  try :
    if not action:
      raise Exception('No action specified')
    if action not in ['start', 'stop']:
      raise Exception('Invalied action specified')

    #print "%sing ctdb on GRIDCell %s."%(action, ','.join(hostname_list))
    r1 = client.cmd(hostname_list, 'cmd.run_all', ['service ctdb %s'%action], expr_form='list')
    #print r1
    if r1:
      for node, ret in r1.items():
        #print ret
        if ret["retcode"] != 0:
          errors = "Error %sing CTDB on %s"%(action, node)
          raise Exception(errors)
    #print "%sed ctdb on GRIDCell %s."%(action, ','.join(hostname_list))

    #Comment the foll out when we use CTDB again!
    """
    #print "%sing winbind on GRIDCell %s."%(action, ','.join(hostname_list))
    r1 = client.cmd(hostname_list, 'cmd.run_all', ['service winbind %s'%action], expr_form='list')
    #print r1
    if r1:
      for node, ret in r1.items():
        #print ret
        if ret["retcode"] != 0:
          errors = "Error %sing winbind on %s"%(action, node)
          raise Exception(errors)
    #print "%sed winbind on GRIDCell %s."%(action, ','.join(hostname_list))
    
    r1 = client.cmd(hostname_list, 'cmd.run_all', ['service smb %s'%action], expr_form='list')
    #print r1
    if r1:
      for node, ret in r1.items():
        #print ret
        if ret["retcode"] != 0:
          errors = "Error %sing smb on %s"%(action, node)
          raise Exception(errors)
    """

  except Exception, e:
    return False, 'Error starting/stopping service : %s'%str(e)
  else:
    return True, None

def chkconfig_services(client, hostname_list, state):
  """Run a chkconfig on ctdb and winbind on the specified nodes.

  client - salt's client handle.
  hostname_list - The list of nodes on which to perform this operation.
  state - either 'on' or 'off'.
  """
  try :
    if not state:
      raise Exception("No state passed")
    if state not in ['on', 'off']:
      raise Exception('Invalid state passed')

    #print "chkconfiging ctdb on GRIDCell %s."%','.join(hostname_list)
    r1 = client.cmd(hostname_list, 'cmd.run_all', ['chkconfig ctdb %s'%state], expr_form='list')
    if r1:
      for node, ret in r1.items():
        #print ret
        if ret["retcode"] != 0:
          errors = "Error chkconfiging CTDB on %s"%node
          raise Exception(errors)
    #print "chkconfiged ctdb on GRIDCell %s."%','.join(hostname_list)

    """
    #print "chkconfiging winbind on GRIDCell %s."%','.join(hostname_list)
    r1 = client.cmd(hostname_list, 'cmd.run_all', ['chkconfig winbind %s'%state], expr_form='list')
    if r1:
      for node, ret in r1.items():
        #print ret
        if ret["retcode"] != 0:
          errors = "Error chkconfiging winbind on %s"%node
          raise Exception(errors)
    #print "chkconfiged winbind on GRIDCell %s."%','.join(hostname_list)

    r1 = client.cmd(hostname_list, 'cmd.run_all', ['chkconfig smb %s'%state], expr_form='list')
    if r1:
      for node, ret in r1.items():
        #print ret
        if ret["retcode"] != 0:
          errors = "Error chkconfiging smb on %s"%node
          raise Exception(errors)
    """
  except Exception, e:
    return False, 'Error chkconfig services : %s'%str(e)
  else:
    return True, None

def create_admin_volume(client, admin_gridcells):

  try :
    admin_vol_name, err = common.get_admin_vol_name()
    if err:
      raise Exception(err)

    print
    print "Creating the bricks for the admin volume"
    r1 = client.cmd(admin_gridcells, 'cmd.run_all', ['zfs create frzpool/normal/%s'%(admin_vol_name)], expr_form='list')
    if r1:
      for node, ret in r1.items():
        #print ret
        if ret["retcode"] != 0:
          raise Exception("Error creating the brick path ZFS dataset on %s"%node)
        else:
          print "Brick path ZFS dataset created on %s"%node

    print
    print "Creating the IntegralStor Administration Volume."

    brick_list = ''
    for admin_gridcell in admin_gridcells:
      brick_list += ' %s:/frzpool/normal/%s'%(admin_gridcell, admin_vol_name)
    cmd = "gluster --mode=script volume create %s repl 2  %s force --xml"%(admin_vol_name, brick_list)
    #print cmd
    #d, err = gluster_commands.run_gluster_command(cmd, "%s/create_volume.xml"%devel_files_path, "Admin volume creation")
    d, err = xml_parse.run_gluster_command(cmd)
    if err:
      raise Exception("Error creating the admin volume : %s"%err)
    print "Creating the IntegralStor Administration Volume... Done."
    print

    '''
    # Not setting quorum for admin vol for now..
    print "Setting trusted pool client side quorum."
    cmd = "gluster volume set %s quorum-count 2 --xml"%admin_vol_name
    d, err = xml_parse.run_gluster_command(cmd)
    if err:
      raise Exception("Error setting trusted pool quorum count : %s"%err)

    cmd = "gluster volume set %s quorum-type fixed --xml"%admin_vol_name
    d, err = xml_parse.run_gluster_command(cmd)
    if err:
      raise Exception("Error setting trusted pool quorum type : %s"%err)
    print "Setting trusted pool client side quorum... Done"
    print
    '''

    print "Starting the IntegralStor Administration Volume."
    d, err = xml_parse.run_gluster_command('gluster volume start %s --xml'%admin_vol_name)
    if err:
      raise Exception("Error starting the admin volume : %s"%err)
    print "Starting the IntegralStor Administration Volume... Done."
    print
    
  except Exception, e:
    return False, 'Error creating the admin volume : %s'%str(e)
  else:
    return True, None


def remove_admin_volume(client):
  try :
    admin_vol_name, err = common.get_admin_vol_name()
    if err:
      raise Exception(err)


    print "Stopping the IntegralStor Administration Volume."
    d, err = xml_parse.run_gluster_command('gluster --mode=script volume stop %s force --xml'%admin_vol_name)
    if err:
      raise Exception("Error stopping the admin volume : %s"%err)
    print "Stopping the IntegralStor Administration Volume... Done."
    print

    cmd = "gluster --mode=script volume delete %s --xml"%admin_vol_name
    #print cmd
    d, err = xml_parse.run_gluster_command(cmd)
    if err:
      raise Exception("Error deleting the admin volume : %s"%err)
    print "Deleting the IntegralStor Administration Volume... Done."
    print

    print "Deleting the bricks for the admin volume"
    r1 = client.cmd('roles:master', 'cmd.run_all', ['zfs destroy frzpool/normal/%s'%(admin_vol_name)], expr_form='grain')
    if r1:
      for node, ret in r1.items():
        #print ret
        if ret["retcode"] != 0:
          errors = "Error deleting the brick path ZFS dataset on %s"%node
          raise Exception(errors)
        else:
          print "Brick path ZFS dataset deleted on %s"%node
          print

  except Exception, e:
    return False, 'Error removing the admin volume : %s'%str(e)
  else:
    return True, None

def check_admin_volume_mountpoint():
  """Check the validity of the mountpoint by trying to open a file there. """
  mountpoint_status = False
  try:
    path, err = common.get_system_status_path()
    if err:
      raise Exception(err)
    try:
      f = open('%s/master.manifest'%path)
      f.close()
      mountpoint_status = True
    except IOError as e:
      mountpoint_status = False

  except Exception, e:
    return False, 'Error checking the admin volume mountpoint : %s'%str(e)
  else:
    return mountpoint_status, None

def mount_admin_volume(client, hostname_list):
  """Mount the gluster admin vol in the default config dir location on the specified nodes.

  client - salt's client handle.
  hostname_list - The list of nodes on which to perform this operation.
  """
  try :
    #Get the name of the admin vol.
    admin_vol_name, err = common.get_admin_vol_name()
    if err:
      raise Exception(err)

    #Get the config dir - the mount point.
    config_dir, err = common.get_config_dir()
    if err:
      raise Exception(err)

    print "Mounting the IntegralStor Administration volume on GRIDCells %s."%','.join(hostname_list)
    r1 = client.cmd(hostname_list, 'cmd.run_all', ['mount -t glusterfs localhost:/%s %s'%(admin_vol_name, config_dir)], expr_form='list')
    #print r1
    if r1:
      for node, ret in r1.items():
        print node, ret
        if ret["retcode"] != 0:
          #print ret['retcode']
          errors = "GRIDCell %s"%node
          raise Exception(errors)
  except Exception, e:
    return False, 'Error mounting the admin volume on: %s'%str(e)
  else:
    return True, None

def unmount_admin_volume(client, hostname_list):
  """Unmount the gluster admin vol on the specified nodes.

  client - salt's client handle.
  hostname_list - The list of nodes on which to perform this operation.
  """
  try :
    #Get the config dir - the mount point.
    config_dir, err = common.get_config_dir()
    if err:
      raise Exception(err)

    #print "Unmounting the IntegralStor Administration volume on GRIDCells %s."%','.join(hostname_list)
    r1 = client.cmd(hostname_list, 'cmd.run_all', ['umount %s'%config_dir], expr_form='list')
    #print r1
    if r1:
      for node, ret in r1.items():
        #print ret
        if ret["retcode"] != 0:
          errors = "GRIDCell : %s"%node
          raise Exception(errors)
  except Exception, e:
    return False, 'Error unmounting the admin volume on : %s'%str(e)
  else:
    return True, None

def add_a_gridcell_to_storage_pool(si, hostname):
  """Performs all necessary oprations required to add a node to the gluster storage pool. In addition to the actual gluster operation, we need to make sure all the other anciliary operations are also performed.

  si - The system info dict needed to pull in all the required info.
  hostname - The hostname of the node to be added.
  """
  return_dict = None
  try:
    error_list = []
    client = None
    ip = None

    if not si:
      raise Exception("Could not determine the configuration of the system!")
    if not hostname: 
      raise Exception("GRIDCell not found!")
    if hostname not in si:
      raise Exception("Could not determine the configuration of the GRIDCell!")

    #Get the bond IP or the hostname
    try :
      ip = si[hostname]["interfaces"]["bond0"]["inet"][0]["address"]
    except Exception, e:
      pass
    if not ip:
      raise Exception("Could not determine the IP of the specified GRIDCell")

    localhost = socket.getfqdn().strip()
    if hostname.lower().strip() == localhost.lower().strip():
      raise Exception('Cannot add the local host to the storage pool.')

    #Now finally good to go ahead and try..
    client = salt.client.LocalClient()

    print 'Stopping services.'
    rc, error = start_or_stop_services(client, [hostname], 'stop')
    if not rc :
      error_list.append(error)
      rc1, err = revert_add_a_gridcell_to_storage_pool(si, client, hostname, ip)
      if err:
        error_list.append(err)
      raise Exception(','.join(error_list))
    print 'Stopped services.'

    print 'adding to the gluster storage pool.'
    return_dict, err  = gluster_trusted_pools.add_a_gridcell_to_gluster_pool(hostname)
    print return_dict, err
    if err:
      error_list.append(err)
      rc1, err = revert_add_a_gridcell_to_storage(si, client, hostname, ip)
      if err:
        error_list.append(err)
      raise Exception(','.join(error_list))
    print 'added to the gluster storage pool.'
  
    '''
    #print 'regenerating manifest and status.'
    rc, err = _regenerate_manifest_and_status(False)
    if not rc:
      error_list.append(err)
      rc1, err = revert_add_a_gridcell_to_storage_pool(si, client, hostname, ip)
      if err:
        error_list.append(err)
      raise Exception(','.join(error_list))
    #print 'regenerated manifest and status.'
    '''
  
    print 'Mounting admin volume.'
    rc, error = mount_admin_volume(client, [hostname])
    if not rc :
      error_list.append(error)
      rc1, err = revert_add_a_gridcell_to_storage_pool(si, client, hostname, ip)
      if err:
        error_list.append(err)
      raise Exception(','.join(error_list))
    print 'Mounted admin volume.'

    
    print 'adding to ctdb nodes file.'
    rc, err = ctdb.add_to_nodes_file([ip])
    print 'added ctdbnode'
    if not rc :
      error_list.append(err)
      rc1, err = revert_add_a_gridcell_to_storage_pool(si, client, hostname, ip)
      if err:
        error_list.append(err)
      raise Exception(','.join(error_list))
    #print 'added to ctdb nodes file.'
        
    
    print 'Placing CTDB files.'
    rc, error = place_ctdb_files(client, [hostname])
    print "Placed the CTDB nodes file on GRIDCell %s."%hostname
    if not rc :
      error_list.append(error)
      rc1, err = revert_add_a_gridcell_to_storage_pool(si, client, hostname, ip)
      if err:
        error_list.append(err)
      raise Exception(','.join(error_list))
    print 'Placed CTDB files.'
    

    print 'Linking Kerberos file.'
    rc, error = link_kerberos_file(client, [hostname])
    print "Linked the Kerberos file on GRIDCell %s."%hostname
    if not rc :
      error_list.append(error)
      rc1, err = revert_add_a_gridcell_to_storage_pool(si, client, hostname, ip)
      if err:
        error_list.append(err)
      raise Exception(','.join(error_list))
    print 'Linked Kerberos file.'
    
    print 'Chkconfiging services.'
    rc, error = chkconfig_services(client, [hostname], 'on')
    if not rc :
      error_list.append(error)
      rc1, err = revert_add_a_gridcell_to_storage_pool(si, client, hostname, ip)
      if err:
        error_list.append(err)
      raise Exception(','.join(error_list))
    print 'Chkconfiged services.'

    print 'Starting services.'
    rc, error = start_or_stop_services(client, [hostname], 'start')
    if not rc :
      error_list.append(error)
      rc1, err = revert_add_a_gridcell_to_storage_pool(si, client, hostname, ip)
      if err:
        error_list.append(err)
      raise Exception(','.join(error_list))
    print 'Started services.'

    print 'copying rc.local files.'
    defaults_dir, err = common.get_defaults_dir()
    if err:
      raise Exception(err)
    r2 = client.cmd(hostname, 'cmd.run_all', ['rm -f /etc/rc.local'])
    r2 = client.cmd(hostname, 'cmd.run_all', ['rm -f /etc/rc.d/rc.local'])
    r2 = client.cmd(hostname, 'cmd.run_all', ['cp %s/rc_local/rc.local /etc/rc.local'%defaults_dir])
    r2 = client.cmd(hostname, 'cmd.run_all', ['chmod 755 /etc/rc.local'])
    if r2:
      for node, ret in r2.items():
        if ret["retcode"] != 0:
          print r2
          errors = "Error setting the appropriate rc.local file on %s"%node
          raise Exception(errors)
    '''
    rc, error = copy_appropriate_rc_local(client, hostname, 'add_to_grid')
    if not rc :
      error_list.append(error)
      rc1, err = revert_add_a_gridcell_to_storage_pool(si, client, hostname, ip)
      if err:
        error_list.append(err)
      raise Exception(','.join(error_list))
    #print 'copyed rc.local files.'
    '''

    
    print 'Reloading CTDB nodes files.'
    rc, err = ctdb.reload_nodes_file(client, [hostname])
    if not rc :
      error_list.append(err)
      rc1, err = revert_add_a_gridcell_to_storage_pool(si, client, hostname, ip)
      if err:
        error_list.append(err)
      raise Exception(','.join(error_list))
    print 'reloaded  ctdb nodes file.'
    

    '''
    #Does not seem to be needed so commenting it out for now.
    #print '8'
    rc, error = set_pool_status(client, [hostname], True)
    #print '8'
    if not rc :
      error_list.append(error)
      rc1, err = revert_add_a_gridcell_to_storage_pool(si, client, hostname, ip)
      if err:
        error_list.append(err)
      raise Exception(','.join(error_list))
    '''
  except Exception, e:
    return None, 'Error adding a GRIDCell to the storage pool : %s'%str(e)
  else:
    return return_dict, None


def revert_add_a_gridcell_to_storage_pool(si, client, hostname, ip):
  """Performs all necessary oprations required to revert the add a node to the gluster storage pool process in case of it failing. 

  si - The system info dict needed to pull in all the required info.
  hostname - The hostname of the node to be added.
  client - salt's client handle.
  ip - The bond IP of the node so we dont have to find it again.
  """

  # This is a revert so its a best effort 
  rc = -1
  try:
    error_list = []
    d, error = gluster_trusted_pools.remove_a_gridcell_from_gluster_pool(hostname)
    if not d and error:
      error_list.append(error)

    rc, error = ctdb.remove_from_nodes_file([ip])
    if not rc and error:
      error_list.append(error)

    if client:
      '''
      #Possibly not needed now.
      rc, error = set_pool_status(client, [hostname], False)
      if not rc  and error:
        error_list.append(error)
      '''

      rc, error = copy_appropriate_rc_local(client, [hostname], 'remove_from_grid')
      if not rc and error:
        error_list.append(error)

      rc, error = start_or_stop_services(client, [hostname], 'stop')
      if not rc and error:
        error_list.append(error)

      rc, error = chkconfig_services(client, [hostname], 'off')
      if not rc and error:
        error_list.append(error)

      
      rc, error = unplace_ctdb_files(client, [hostname])
      if not rc  and error:
        error_list.append(error)
      

      rc, error = unmount_admin_volume(client, [hostname])
      if not rc and error:
        error_list.append(error)

    if error_list:
      raise Exception(','.join(error_list))
  except Exception, e:
    return False, 'Error reverting GRIDCell addition : %s'%str(e)
  else:
    return True, None


def remove_a_gridcell_from_storage_pool(si, hostname):
  """Performs all necessary oprations required to remove a node from the gluster storage pool. In addition to the actual gluster operation, we need to make sure all the other anciliary operations are also performed.

  si - The system info dict needed to pull in all the required info.
  hostname - The hostname of the node to be removed.
  """
  return_dict = None
  try :
    client = None
    ip = None
    error_list = []
    try :
      ip = si[hostname]["interfaces"]["bond0"]["inet"][0]["address"]
    except Exception, e:
      pass

    client = salt.client.LocalClient()
    '''
    #Possibly not needed now
    rc, error = set_pool_status(client, [hostname], False)
    if not rc :
      error_list.append(error)
      rc1, err = revert_remove_a_gridcell_from_storage_pool(si, client, hostname, ip)
      if err:
        error_list.append(err)
      raise Exception(','.join(error_list))
    '''

    #print 'Copying appropriate rc_local files'
    rc, error = copy_appropriate_rc_local(client, hostname, 'remove_from_grid')
    if not rc :
      error_list.append(error)
      rc1, err = revert_remove_a_gridcell_from_storage_pool(si, client, hostname, ip)
      if err:
        error_list.append(err)
      raise Exception(','.join(error_list))
    #print 'Copyed appropriate rc_local files'

    print 'Stopping services'
    rc, error = start_or_stop_services(client, [hostname], 'stop')
    if not rc :
      error_list.append(error)
      rc1, err = revert_remove_a_gridcell_from_storage_pool(si, client, hostname, ip)
      if err:
        error_list.append(err)
      raise Exception(','.join(error_list))
    print 'Stopped services'

    print 'Chkconfiging services off'
    rc, error = chkconfig_services(client, [hostname], 'off')
    if not rc :
      error_list.append(error)
      rc1, err = revert_remove_a_gridcell_from_storage_pool(si, client, hostname, ip)
      if err:
        error_list.append(err)
      raise Exception(','.join(error_list))
    print 'Chkconfiged services off'

    
    print 'Unplacing ctdb files'
    rc, error = unplace_ctdb_files(client, [hostname])
    if not rc :
      error_list.append(error)
      rc1, err = revert_remove_a_gridcell_from_storage_pool(si, client, hostname, ip)
      if err:
        error_list.append(err)
      raise Exception(','.join(error_list))
    print 'Unplaced ctdb files'
    

    print 'Unmounting admin vol'
    rc, error = unmount_admin_volume(client, [hostname])
    if not rc :
      error_list.append(error)
      rc1, err = revert_remove_a_gridcell_from_storage_pool(si, client, hostname, ip)
      if err:
        error_list.append(err)
      raise Exception(','.join(error_list))
    print 'Unmounted admin vol'

    print 'Removing from ctdb nodes file'
    rc, err = ctdb.remove_from_nodes_file([ip])
    if not rc :
      error_list.append(err)
      rc1, err = revert_remove_a_gridcell_from_storage_pool(si, client, hostname, ip)
      if err:
        error_list.append(err)
      raise Exception(','.join(error_list))
    print 'Removed from ctdb nodes file'

    print 'Removing from the gluster pool'
    return_dict, err  = gluster_trusted_pools.remove_a_gridcell_from_gluster_pool(si, hostname)
    if not d:
      error_list.append(err)
      rc1, err = revert_remove_a_gridcell_from_storage_pool(si, client, hostname, ip)
      if err:
        error_list.append(err)
      raise Exception(','.join(error_list))
    print 'Removed from the gluster pool'

  except Exception, e:
    print str(e)
    return d, 'Error removing a GRIDCell from the storage pool : %s'%str(e)
  else:
    return d, None

def revert_remove_a_gridcell_from_storage_pool(si, client, hostname, ip):
  """Performs all necessary oprations required to revert the remove a node to the gluster storage pool process in case of it failing. 

  si - The system info dict needed to pull in all the required info.
  hostname - The hostname of the node to be added.
  client - salt's client handle.
  ip - The bond IP of the node so we dont have to find it again.
  """

  # This is a revert so its a best effort 
  try:
    error_list = []

    d, error = gluster_trusted_pools.add_a_gridcell_to_gluster_pool(hostname)
    if error:
      error_list.append(error)

    
    rc, error = ctdb.add_to_nodes_file([ip])
    if not rc  and error:
      error_list.append(error)
    

    if client:
      rc, error = mount_admin_volume(client, [hostname])
      if not rc  and error:
        error_list.append(error)

      
      rc, error = place_ctdb_files(client, [hostname])
      if not rc  and error:
        error_list.append(error)
      

      rc, error = chkconfig_services(client, [hostname], 'on')
      if not rc  and error:
        error_list.append(error)

      rc, error = start_or_stop_services(client, [hostname], 'start')
      if not rc and error:
        error_list.append(error)

      rc, error = copy_appropriate_rc_local(client, hostname, 'add_to_grid')
      if not rc  and error:
        error_list.append(error)

      rc, error = set_pool_status(client, [hostname], True)
      if not rc  and error:
        error_list.append(error)

    if error_list:
      raise Exception(','.join(error_list))
  except Exception, e:
    return False, 'Error reverting a GRIDCell removal from  the storage pool : %s'%str(e)
  else:
    return True, None

def add_gridcells_to_grid(request_meta,pending_minions, admin_gridcell_list, first_time = False, print_progress = False, admin_gridcells = False, restart_salt_minions = True, establish_cron = True):
  """Add the specified set of gridcells to the salt masters and to DNS and sync our salt modules with them.

  remote_addr - The address of the integralview admin's browser for audit purposes..
  pending_minions - The set of pending salt minions to be accepted
  admin_gridcell_list - The list of admin GRIDCells. This is used to update the minion config file to point to the appropriate masters
  first_time - Is this being called from the first time setup or not?
  print_progress - Shd we print progress messages onto the console?
  admin_gridcells - Are the gridcells being added admin GRIDCells? If so, we need to put in the appropriate grains to flag them as so.
  """

  successful_gridcells = []
  failed_gridcells = []
  errors = ""
  try:
    #The list of minions that got accepted but some following operations failed after that.
    accepted_failed_minions = []
    print_progress = True

    if pending_minions:
      ip = None

      #Get the salt handles
      client = salt.client.LocalClient()
      wheel, err = get_salt_wheel()
      if err:
        raise Exception(err)

      #Should we print the progress on the console or not?
      if print_progress:
        print "Accepting the following GRIDCells : %s"%','.join(pending_minions)
      
      accept_results, err = accept_salt_keys(wheel, pending_minions, print_progress)
      if err:
        raise Exception(err)


      if print_progress and accept_results and 'accepted_gridcells' in accept_results:
        print 'Accepted GRIDCells %s.'%','.join(accept_results['accepted_gridcells'])

      if 'accepted_gridcells' in accept_results and accept_results['accepted_gridcells']:
        successful_gridcells.extend(accept_results['accepted_gridcells'])

        #Instead, keep pinging the hosts to make sure they are all contactable before continuing..
        pending_response_list = list(successful_gridcells)
        r1 = client.cmd(pending_response_list, 'test.ping', expr_form='list')
        count = 1
        while count <= 60:
          print 'count - ', count
          if r1:
            for gridcell_hostname, result in r1.items():
              if result:
                pending_response_list.remove(gridcell_hostname)
          print 'pending response list - ', pending_response_list
          if pending_response_list:
            #Sigh! Someone's not responded so try again!
            count = count + 1
            time.sleep(1)
            r1 = client.cmd(pending_response_list, 'test.ping', expr_form='list')
          else:
            #Phew! Done early so break out
            print 'breaking'
            break
        if pending_response_list:
          failed_gridcells.extend(pending_response_list)
          for n in pending_response_list:
            successful_gridcells.remove(n)

        if successful_gridcells:
          #Some succeeded so sync salt modules to those and regenerate the manifest and status.
          if print_progress:
            print
            print "Syncing modules to GRIDCells"
          rc, err = sync_salt_modules(client, successful_gridcells)
          if err:
            raise Exception(err)
          if print_progress:
            print "Syncing modules to GRIDCells.. Done."
            print
          #Now poll till we get a response from the module on all those gridcells
          pending_response_list = list(successful_gridcells)
          r1 = client.cmd(pending_response_list, 'integralstor.status', expr_form='list')
          count = 1
          while count <= 60:
            print 'count - ', count
            if r1:
              for gridcell_hostname, result in r1.items():
                if isinstance(result,dict):
                  pending_response_list.remove(gridcell_hostname)
              print 'pending response list - ', pending_response_list
              if pending_response_list:
                #Sigh! Someone's not responded so try again!
                count = count + 1
                time.sleep(1)
                r1 = client.cmd(pending_response_list, 'integralstor.status', expr_form='list')
              else:
                #Phew! Done early so break out
                print 'breaking'
                break

          '''
          if print_progress:
            print "\nPausing 30 seconds to allow for modules sync\n"
          time.sleep(30)
          '''

          minion_list, err = get_accepted_minions()
          if err:
            successful_gridcells = []
            failed_gridcells = list(accept_results['accepted_gridcells']) 

        if successful_gridcells and minion_list:
          if print_progress:
            print 
            print 'Getting bond0 IP for GRIDCells.'

          mapping_dict, err = get_minion_ips(client, minion_list)
          if err:
            successful_gridcells = []
            failed_gridcells = list(accept_results['accepted_gridcells']) 

          for gridcell_hostname in successful_gridcells:
            #Add the IP/HN of the new gridcells to all the current minions
            ret, err = dns.add_to_dns(client, gridcell_hostname, mapping_dict[gridcell_hostname])
            if err:
              successful_gridcells.remove(gridcell_hostname)
              failed_gridcells.append(gridcell_hostname)
            #Populate the IP/HN of the all the current minions into the new gridcell
            ret, err = dns.populate_hosts_file(client, gridcell_hostname, mapping_dict)
            if err:
              successful_gridcells.remove(gridcell_hostname)
              failed_gridcells.append(gridcell_hostname)
            else:
              #All went well so audit and continue to the next
              if print_progress:
                print "Successfully added GRIDCell %s to the grid."%gridcell_hostname
    
              #If it is part of the first time setup, then dont audit..
              if not first_time:
                ret, err = audit.audit("hardware_scan_node_added", "Added a new GRIDCell %s to the grid"%gridcell_hostname,request_meta )
                if err:
                  errors += err

  
        #Some failed so kick off minion restart and then delete their keys so that we can try again later
        if failed_gridcells:
          if print_progress:
            print 'Failed minions : ', failed_gridcells
          ret, err = restart_minions(client, failed_gridcells)
          if err:
            errors += err
          for gridcell_hostname in failed_gridcells:
            r, err = delete_salt_key(gridcell_hostname)
            if (not r) and err:
              errors += err
  
        if successful_gridcells:

          if print_progress:
            print "Regenerating manifest and status"

          #We now have a new minion so we need to update the manifest so that the appropriate status for the new minions will also get pulled in.
          rc, err = _regenerate_manifest_and_status(first_time)
          if not rc  :
            if err:
              errors += err
            else:
              errors += 'Error regenerating manifest and status'
          else:
            if print_progress:
              print "Regenerated manifest and status"
              print
          if establish_cron:
            setup_cron(client, pending_minions, admin_gridcells)
  
          #print "Successfully added : %s"%successful_gridcells
          #print "Failed adding : %s"%failed_gridcells
  
          try:
            #rc = client.cmd(gridcell_hostname,'file.copy',['/opt/integralstor/integralstor_gridcell/defaults/salt/minion','/etc/salt/minion',True])
            rc = client.cmd(successful_gridcells,'integralstor.configure_minion',admin_gridcell_list, expr_form='list')
            if admin_gridcells:
              rc = client.cmd(successful_gridcells,'integralstor.flag_as_admin_gridcell', expr_form='list')
            if restart_minions:
              rc = client.cmd(successful_gridcells,'cmd.run',['echo service salt-minion restart | at now + 1 minute'], expr_form='list')
          except Exception,e:  
            raise Exception(e)
  

      if  'failed_gridcells' in accept_results and accept_results['failed_gridcells']:
        failed_gridcells.extend(accept_results['failed_gridcells'])

      if errors:
        raise Exception(errors)
  except Exception, e:
    if errors:
      err = errors + ' ' + str(e)
    else:
      err = str(e)
    return (successful_gridcells, failed_gridcells), 'Error adding GRIDCells to the grid : %s'%err
  else:
    return (successful_gridcells, failed_gridcells), None

def remove_a_gridcell_from_grid(gridcell_name):
  try:
    client = salt.client.LocalClient()
    print 'b'
    ret, err = undo_setup_cron(client, [gridcell_name])
    print ret, err
    if err:
      raise Exception(err)
    minion_list, err = get_accepted_minions()
    if err:
      raise Exception(err)
    mapping_dict, err = get_minion_ips(client, minion_list)
    if err:
      raise Exception(err)
    ret, err = dns.remove_from_dns(client, gridcell_name)
    print ret, err
    ret, err = dns.unpopulate_hosts_file(client, gridcell_name, mapping_dict)
    print ret, err
    rc = client.cmd(gridcell_name,'cmd.run_all',['echo service salt-minion restart | at now + 1 minute'])
    status, err = delete_salt_key(gridcell_name)
    if err:
      raise Exception(err)
    status,err = _regenerate_manifest_and_status()
    if err:
      raise Exception(err)
  except Exception, e:
    return False , 'Error removing GRIDCell from the grid : %s'%e
  else:
    return True, None

def is_active_admin_gridcell():
  """Scrolls down the list of admin gridcells and tells us if the calling gridcell is the active one that needs to run the scripts"""
  active = False
  try:
    me = socket.getfqdn()
    platform_root, err = common.get_platform_root()
    if err:
      raise Exception(err)
    with open('%s/admin_gridcells'%platform_root, 'r') as f:
      hosts = f.readlines()
    #print 'i am ', me
    for host in hosts:
      #print 'checking ', host
      if host.strip() == me:
        #print 'its my turn now to execute!'
        active = True
        break
      ret, err = networking.can_ping(host)
      if err:
        raise Exception(err)
      if ret:
        #print 'can ping so bailing out'
        break
  except Exception, e:
    return None, 'Error determining if active admin GRIDCell : %s'%err
  else:
    return active, None

def is_part_of_grid():
  """ Check if the local node is part of the grid"""
  part = False
  try:
    platform_root, err = common.get_platform_root()
    if err:
      raise Exception(err)
    if os.path.isfile('%s/part_of_grid'%platform_root):
      part = True
  except Exception, e:
    return False, 'Error checking for grid membership : %s'%str(e)
  else:
    return part, None

def is_admin_gridcell():
  """Check if the local node is an admin gridcell"""
  admin = False
  try:
    me = socket.getfqdn()
    platform_root, err = common.get_platform_root()
    if err:
      raise Exception(err)
    if os.path.isfile('%s/admin_gridcells'%platform_root):
      lines = []
      with open('%s/admin_gridcells'%platform_root, 'r') as f:
        lines = f.readlines()
      for line in lines:
        if line.strip() == me:
          admin = True
          break
  except Exception, e:
    return False, 'Error checking for admin grid membership : %s'%str(e)
  else:
    return admin, None
    
def get_admin_gridcells():
  """Get the list of admin gridcells"""
  admin_gridcells = []
  try:
    platform_root, err = common.get_platform_root()
    if err:
      raise Exception(err)
    if os.path.isfile('%s/admin_gridcells'%platform_root):
      lines = []
      with open('%s/admin_gridcells'%platform_root, 'r') as f:
        lines = f.readlines()
      admin_gridcells = [line.strip() for line in lines]
  except Exception, e:
    return None, 'Error getting admin GRIDCells: %s'%str(e)
  else:
    return admin_gridcells, None

def is_admin_vol_mounted_local():
  """Check if the gluster admin vol is mounted on the local node."""
  mounted = False
  try:
    admin_vol_name, err = common.get_admin_vol_name()
    if err:
      raise Exception(err)
    config_dir, err = common.get_config_dir()
    if err:
      raise Exception(err)
    with open('/proc/self/mounts', 'r') as f:
      for line in f:
        if admin_vol_name in line and config_dir in line:
          mounted = True
          break
  except Exception, e:
    return False, 'Error checking if admin volume is mounted : %s'%str(e)
  else:
    return mounted, None

def is_admin_vol_mounted_grid(client, hostname_list):
  """Check if the gluster admin vol is mounted on the specified nodes.

  Returns a True or False for each host in hostname_list

  client - salt's client handle.
  hostname_list - The list of nodes on which to perform this operation.
  """
  return_dict = {}
  try :
    #Get the config dir - the mount point.
    config_dir, err = common.get_config_dir()
    if err:
      raise Exception(err)

    r1 = client.cmd(hostname_list, 'mount.is_mounted', [config_dir], expr_form='list')
    #print r1
    if r1:
      for node, ret in r1.items():
        return_dict[node] = ret
    else:
      raise Exception('No response from GRIDCells')
  except Exception, e:
    return None, 'Error checking admin volume mountpoint : %s'%str(e)
  else:
    return return_dict, None

def setup_cron(client, hostname_list, admin_gridcells = False):
  try :
    jobs = [ 
      ['*','*','*','*','*','/usr/bin/python /opt/integralstor/integralstor_gridcell/scripts/python/mount_admin_volume.py > /tmp/mount_admin_vol_out >> /tmp/mount_admin_vol_err'], 
      ['*','*','*','*','*','/usr/bin/python /opt/integralstor/integralstor_common/scripts/python/task_processor.py > /tmp/task_processor_output >> /tmp/task_processor_errors'], 
      ['*','*','*','*','*','/usr/bin/python /opt/integralstor/integralstor_gridcell/scripts/python/batch_process.py > /tmp/batch_process_output >> /tmp/batch_process_errors'], 
      ['*','*','*','*','*','/usr/bin/python /opt/integralstor/integralstor_gridcell/scripts/python/monitoring.py generate_status_file > /tmp/generate_status_file_output >> /tmp/generate_status_file_errors'], 
      ['*','*','*','*','*','/usr/bin/python /opt/integralstor/integralstor_gridcell/scripts/python/log_backup.py backup_gridcell_logs > /tmp/gridcell_log_backup_output >> /tmp/gridcell_log_backup_errors'], 
      ['*','*','*','*','*','/usr/bin/python /opt/integralstor/integralstor_gridcell/scripts/python/config_backup.py backup_gridcell_config > /tmp/gridcell_config_backup_output >> /tmp/gridcell_config_backup_errors']]

    admin_jobs = [
      ['*/2','*','*','*','*','/usr/bin/python /opt/integralstor/integralstor_gridcell/scripts/python/log_backup.py backup_grid_logs > /tmp/grid_log_backup_output >> /tmp/grid_log_backup_errors'], 
      ['*','*','*','*','*','/usr/bin/python /opt/integralstor/integralstor_common/scripts/python/generate_status.py > /tmp/status_output >> /tmp/status_errors'], 
      ['*','*','*','*','*','/usr/bin/python /opt/integralstor/integralstor_gridcell/scripts/python/poll_for_alerts.py > /tmp/gridcell_poll_for_alerts_output >> /tmp/gridcell_poll_for_alerts_errors'], 
      ['0','0','*','*','*','/usr/bin/python -c "from integralstor_common import logs; logs.auto_rotate_logs()" > /tmp/auto_rotate_logs_alerts >> /tmp/auto_rotate_errors']]
    if admin_gridcells:
      jobs.extend(admin_jobs)
    for job in jobs:
      job.insert(0, 'root')
      rc = client.cmd(hostname_list,'cron.set_job', job, expr_form='list')
      #print job
      #print rc
      for node, ret in rc.items():
        if ret not in ['new', 'updated']:
          raise Exception('Error installing cron job %s on node %s'%(job, node))
  except Exception, e:
    return False, 'Error setting up cron : %s'%str(e)
  else:
    return True, None

def undo_setup_cron(client, hostname_list, admin_gridcells = False):
  try :
    jobs = [ 
      ['/usr/bin/python /opt/integralstor/integralstor_gridcell/scripts/python/mount_admin_volume.py > /tmp/mount_admin_vol_out >> /tmp/mount_admin_vol_err'], 
      ['/usr/bin/python /opt/integralstor/integralstor_common/scripts/python/run_scheduler.py > /tmp/scheduler_output >> /tmp/scheduler_errors'], 
      ['/usr/bin/python /opt/integralstor/integralstor_gridcell/scripts/python/batch_process.py > /tmp/batch_process_output >> /tmp/batch_process_errors'], 
      ['/usr/bin/python /opt/integralstor/integralstor_gridcell/scripts/python/log_backup.py backup_gridcell_logs > /tmp/gridcell_log_backup_output >> /tmp/gridcell_log_backup_errors'], 
      ['/usr/bin/python /opt/integralstor/integralstor_gridcell/scripts/python/config_backup.py backup_gridcell_config > /tmp/gridcell_config_backup_output >> /tmp/gridcell_config_backup_errors']]

    admin_jobs = [
      ['/usr/bin/python /opt/integralstor/integralstor_common/scripts/python/generate_status.py > /tmp/status_output >> /tmp/status_errors'], 
      ['/usr/bin/python /opt/integralstor/integralstor_gridcell/scripts/python/poll_for_alerts.py > /tmp/gridcell_poll_for_alerts_output >> /tmp/gridcell_poll_for_alerts_errors'], 
      ['/usr/bin/python -c "from integralstor_common import logs; logs.auto_rotate_logs()" > /tmp/auto_rotate_logs_alerts >> /tmp/auto_rotate_errors']]
    if admin_gridcells:
      jobs.extend(admin_jobs)
    for job in jobs:
      job.insert(0, 'root')
      rc = client.cmd(hostname_list,'cron.rm_job', job, expr_form='list')
      print job
      print rc
      for node, ret in rc.items():
        if ret not in ['removed', 'absent']:
          raise Exception('Error removing cron job %s on node %s'%(job, node))
  except Exception, e:
    return False, 'Error setting up cron : %s'%str(e)
  else:
    return True, None
  
def main():
  #_regenerate_manifest_and_status(True)
  #add_nodes_to_grid("1.1.1.1",['a', 'b'], first_time = False, accessing_from = 'primary')
  pass

if __name__ == "__main__":
  main()

  """
      if wheel.call_func('key.accept', match=('%s'%m)):
	      time.sleep(20)
        command_to = 'salt %s saltutil.sync_all'%(m)
        ret, ret_code = command.execute_with_rc(command_to)
        #print ret, ret_code
        time.sleep(20)
        r = client.cmd(m, 'grains.item', ['ip_interfaces'], timeout=180)
        #print r
        if r:
          #print r[m]
          #print r[m]['ip_interfaces']
          #print r[m]['ip_interfaces']['bond0']
          if 'ip_interfaces' in r[m] and r[m]['ip_interfaces']['bond0']:
            ip = r[m]['ip_interfaces']['bond0'][0]
            print "Found Bond IP : %s"%ip
          else:
            print "Could not find the Bond IP"
        if ip:
          print "Adding %s to DNS"%m
          r1 = client.cmd('roles:primary', 'ddns.add_host', ['integralstor.lan', m, 86400, ip], expr_form='grain', timeout=180)
          print "Added %s to DNS"%m
          if not r1:
            errors = "Error adding the DNS information for GRIDCell %s"%m
            print "Error adding DNS information for GRIDCell %s"%m
          else:
            audit.audit("hardware_scan_node_added", "Added a new GRIDCell %s to the grid"%m,remote_addr )
            success.append(m)
        else:
            errors = "Error adding the DNS information for %s. No IP address information found."%m
            print "Error retrieving the IP from GRIDCell %s"%m
      else:
        failed.append(m)
    #print "Successfully added : %s"%success
    #print "Failed adding : %s"%failed
    print "Regenerating manifest and status"
    rc, err = _regenerate_manifest_and_status(first_time)
    print "Regenerated manifest and status"
    if not rc :
      if errors:
        errors += "Error regenerating the new configuration : "
      else:
        errors = "Error regenerating the new configuration : "
      errors += ",".join(command.get_output_list(ret))
      errors += ",".join(command.get_error_list(ret))
    #From regenerate_manifest_status
    manifest_command = "%s/generate_manifest.py %s"%(common_python_scripts_path, path)
    #print manifest_command
    (ret, rc), err = command.execute_with_rc(manifest_command)
    #print ret, rc
    if err:
      raise Exception(err)
    if rc != 0:
      errors = "Error regenerating the new manifest: "
      o, err = command.get_output_list(ret)
      if o:
        errors += ",".join(o)
      e, err = command.get_error_list(ret)
      if e:
        errors += ",".join(e)
      raise Exception(errors)
    status_command = "%s/generate_status.py %s"%(common_python_scripts_path, path)
    #print status_command
    (ret, rc), err = command.execute_with_rc(status_command)
    if err:
      raise Exception(err)
    #print ret, rc
    if rc != 0:
      errors = "Error regenerating the new status : "
      o, err = command.get_output_list(ret)
      if o:
        errors += ",".join(o)
      e, err = command.get_error_list(ret)
      if e:
        errors += ",".join(e)
      raise Exception(errors)

def set_pool_status(client, hostname_list, part_of_pool):
  #This is probably not needed anymore. Keeping just until we confirm.

  try :
    platform_root, err = common.get_platform_root()
    if err:
      raise Exception(err)
    if part_of_pool:
      cmd = 'touch %s/part_of_pool'%platform_root
    else:
      cmd = 'rm %s/part_of_pool'%platform_root

    r1 = client.cmd(hostname_list, 'cmd.run_all', [cmd], expr_form='list')
    #print r1
    if r1:
      for node, ret in r1.items():
        #print ret
        if ret["retcode"] not in [0, 1]:
          errors = "GRIDCell %s"%node
          raise Exception(errors)
  except Exception, e:
    return False, 'Error setting pool status : %s'%str(e)
  else:
    return True, None
  """
