import salt.client, salt.wheel

import socket, time

from integralstor_common import command, audit, common
from integralstor_gridcell import ctdb, gluster_commands

def _regenerate_manifest_and_status(first_time = False):
  rc = -1
  try:
    if first_time:
      path, err = common.get_tmp_path()
      if err:
        raise Exception(err)
    else:
      path, err = common.get_system_status_path()
      if err:
        raise Exception(err)
    scripts_path, err = common.get_python_scripts_path()
    if err:
      raise Exception(err)
    common_python_scripts_path, err = common.get_common_python_scripts_path()
    if err:
      raise Exception(err)
    manifest_command = "%s/generate_manifest.py %s"%(common_python_scripts_path, path)
    #print manifest_command
    (ret, rc), err = command.execute_with_rc(manifest_command)
    #print ret, rc
    if err:
      raise Exception(err)
    if rc != 0:
      errors = "Error regenerating the new manifest: "
      o, err = command.get_output_list(ret)
      if o:
        errors += ",".join(o)
      e, err = command.get_error_list(ret)
      if e:
        errors += ",".join(e)
      raise Exception(errors)
    status_command = "%s/generate_status.py %s"%(common_python_scripts_path, path)
    #print status_command
    (ret, rc), err = command.execute_with_rc(status_command)
    if err:
      raise Exception(err)
    #print ret, rc
    if rc != 0:
      errors = "Error regenerating the new status : "
      o, err = command.get_output_list(ret)
      if o:
        errors += ",".join(o)
      e, err = command.get_error_list(ret)
      if e:
        errors += ",".join(e)
      raise Exception(errors)
  except Exception, e:
    return False, 'Error regenerating the new configuration : %s'%str(e)
  else:
    return True, None


def get_accepted_minions():
  minion_list = []
  try :
    cfg, err = common.get_salt_master_config()
    if err:
      raise Exception(err)
    opts = salt.config.master_config(cfg)
    wheel = salt.wheel.Wheel(opts)
    keys = wheel.call_func('key.list_all')
    if keys:
      minion_list = keys['minions']
  except Exception, e:
    return None, "Error retrieving accepted minions : %s"%str(e)
  else:
    return minion_list, None

def get_pending_minions():
  pending_minions = None
  try:
    cfg, err = common.get_salt_master_config()
    if err:
      raise Exception(err)
    opts = salt.config.master_config(cfg)
    wheel = salt.wheel.Wheel(opts)
    keys = wheel.call_func('key.list_all')
    if keys:
      pending_minions = keys['minions_pre']
  except Exception, e:
    return None, 'Error retrieving pending minions : %s'%str(e)
  else:
    return pending_minions, None

def restart_minions(client, minion_list):
  try:
    r1 = client.cmd(minion_list, 'cmd.run', ['echo service salt-minion restart | at now + 1 minute'], expr_form='list')
  except Exception, e:
    return False, 'Error restarting minions : %s'%str(e)
  else:
    return True, None

def accept_salt_key(wheel, m):
  ret = -1
  try:
    if not wheel or not m:
      raise Exception('Required parameters not passed')
    if not wheel.call_func('key.accept', match=('%s'%m)):
      raise Exception('GRIDCell %s'%m)
    else:
      ret = 0
  except Exception, e:
    return False, 'Error accepting GRIDCell key : %s'%str(e)
  else:
    return True, None

def delete_salt_key(hostname):
  try:
    cfg, err = common.get_salt_master_config()
    if err:
      raise Exception(err)
    opts = salt.config.master_config(cfg)
    wheel = salt.wheel.Wheel(opts)
    keys = wheel.call_func('key.list_all')
    if (not keys) or ('minions' not in keys) or (hostname not in keys['minions']):
      raise Exception("Specified GRIDCell is not part of the grid")
    wheel.call_func('key.delete', match=(hostname))
  except Exception, e:
    errors = "Error removing GRIDCell key from the grid : %s"%str(e)
    return False, errors
  else:
    return True, None

def sync_salt_modules(client, minion_list):
  try:
    rc = client.cmd(minion_list, 'saltutil.sync_modules', expr_form='list')
  except Exception, e:
    return False, 'Error syncing salt modules : %s'%str(e)
  else:
    return True, None

def get_minion_ip(client, m):
  ip = None
  try:
    r = client.cmd(m, 'grains.item', ['ip_interfaces'])
    #print r
    if r:
      if 'ip_interfaces' in r[m] and r[m]['ip_interfaces']['bond0']:
        ip = r[m]['ip_interfaces']['bond0'][0]
      else:
        raise Exception("Could not retrieve the IP for GRIDCell %s"%m)
    else:
      raise Exception("Could not retrieve the IP for GRIDCell %s"%m)
  except Exception, e:
    return None, 'Error retrieving minion IP address : %s'%str(e)
  else:
    return ip, None

def add_to_dns(client, m, ip):
  try:
    # Dont add the primary and secondary because they are alread there!
    if m not in ['gridcell-pri.integralstor.lan', 'gridcell-sec.integralstor.lan', 'gridcell-pri', 'gridcell-sec']:
      r1 = client.cmd('roles:primary', 'ddns.add_host', ['integralstor.lan', m, 86400, ip], expr_form='grain', timeout=180)
      print r1
      #print "Added %s to DNS"%m
      if not r1:
        raise Exception("GRIDCell %s"%m)
      else:
        for key, value in r1.items():
          if value is not None and value==False:
            raise Exception("GRIDCell %s"%m)
  except Exception, e:
    return False, "Error adding a GRIDCell to DNS : %s"%str(e)
  else:
    return True, None

def remove_from_dns(client, m, ip):
  try:
    r1 = client.cmd('roles:primary', 'ddns.delete_host', ['integralstor.lan', m], expr_form='grain', timeout=180)
    if not r1:
      raise Exception("GRIDCell %s"%m)
  except Exception, e:
     return False, "Error removing DNS information for GRIDCell : %s"%str(e)
  else:
    return True, None


def link_ctdb_files(client, hostname_list):
  try :
    config_dir, err = common.get_config_dir()
    if err:
      raise Exception(err)
    #print "Removing original CTDB config file on GRIDCell %s."%','.join(hostname_list)
    r1 = client.cmd(hostname_list, 'cmd.run_all', ['rm /etc/sysconfig/ctdb'], expr_form='list')
    #print "Removed original CTDB config file on GRIDCell %s."%','.join(hostname_list)
    #print "Linking the CTDB config file on GRIDCell %s."%','.join(hostname_list)
    r1 = client.cmd(hostname_list, 'cmd.run_all', ['ln -s %s/lock/ctdb /etc/sysconfig/ctdb'%config_dir], expr_form='list')
    if r1:
      for node, ret in r1.items():
        #print ret
        if ret["retcode"] != 0:
          errors = 'Error linking ctdb config file on GRIDCell %s'%node
          raise Exception(errors)
    #print "Linked the CTDB config file on GRIDCell %s."%','.join(hostname_list)

    #print "Removing original CTDB nodes file on GRIDCell %s."%','.join(hostname_list)
    r1 = client.cmd(hostname_list, 'cmd.run_all', ['rm /etc/ctdb/nodes'], expr_form='list')
    #print "Removed original CTDB nodes file on GRIDCell %s."%','.join(hostname_list)
    #print "Linking the CTDB nodes file on GRIDCell %s."%','.join(hostname_list)
    r1 = client.cmd(hostname_list, 'cmd.run_all', ['ln -s %s/lock/nodes /etc/ctdb/nodes'%config_dir], expr_form='list')
    if r1:
      for node, ret in r1.items():
        #print ret
        if ret["retcode"] != 0:
          errors = "Error linking the CTDB nodes file on GRIDCell %s"%node
          #Undo the previous linking
          r1 = client.cmd(hostname_list, 'cmd.run_all', ['rm /etc/sysconfig/ctdb'], expr_form='list')
          return -1, errors
  except Exception, e:
    error_str = str(e)
    return False, error_str
  else:
    return True, None

def unlink_ctdb_files(client, hostname_list):
  try :
    r1 = client.cmd(hostname_list, 'cmd.run_all', ['rm /etc/sysconfig/ctdb'], expr_form='list')
    r1 = client.cmd(hostname_list, 'cmd.run_all', ['rm /etc/ctdb/nodes'], expr_form='list')
  except Exception, e:
    err = "Error removing CTDB files : %s"%str(e)
    return False, err
  else:
    return True, None

def copy_appropriate_rc_local(client, hostname_list, action):
  try :
    defaults_dir, err = common.get_defaults_dir()
    if err:
      raise Exception(err)
    if not action:
      raise Exception('No action specified')
    if action not in ['add_to_grid', 'remove_from_grid']:
      raise Exception('Invalied action specified')
    if action == 'add_to_grid':
      cmd = 'cp %s/rc_local/normal/rc.local.in_cluster /etc/rc.local'%defaults_dir
    else:
      cmd = 'cp %s/rc_local/normal/rc.local.not_in_cluster /etc/rc.local'%defaults_dir
    #print cmd
    r1 = client.cmd(hostname_list, 'cmd.run_all', [cmd], expr_form='list')
    #print r1
    if r1:
      for node, ret in r1.items():
        #print ret
        if ret["retcode"] != 0:
          errors = "Error copying on GRIDCell %s"%node
          raise Exception(errors)
    cmd = 'chmod 755 /etc/rc.local'
    r1 = client.cmd(hostname_list, 'cmd.run_all', [cmd], expr_form='list')
    #print r1
    if r1:
      for node, ret in r1.items():
        #print ret
        if ret["retcode"] != 0:
          errors = "Error changing permissions on GRIDCell %s"%node
          raise Exception(errors)
  except Exception, e:
    return False, 'Error placing rc.local : %s'%str(e)
  else:
    return True, None

def start_or_stop_services(client, hostname_list, action):
  try :
    if not action:
      raise Exception('No action specified')
    if action not in ['start', 'stop']:
      raise Exception('Invalied action specified')
    #print "%sing ctdb on GRIDCell %s."%(action, ','.join(hostname_list))
    r1 = client.cmd(hostname_list, 'cmd.run_all', ['service ctdb %s'%action], expr_form='list')
    #print r1
    if r1:
      for node, ret in r1.items():
        #print ret
        if ret["retcode"] != 0:
          errors = "Error %sing CTDB on %s"%(action, node)
          raise Exception(errors)
    #print "%sed ctdb on GRIDCell %s."%(action, ','.join(hostname_list))
    #print "%sing winbind on GRIDCell %s."%(action, ','.join(hostname_list))
    r1 = client.cmd(hostname_list, 'cmd.run_all', ['service winbind %s'%action], expr_form='list')
    #print r1
    if r1:
      for node, ret in r1.items():
        #print ret
        if ret["retcode"] != 0:
          errors = "Error %sing winbind on %s"%(action, node)
          raise Exception(errors)
    #print "%sed winbind on GRIDCell %s."%(action, ','.join(hostname_list))
  except Exception, e:
    return False, 'Error starting/stopping service : %s'%str(e)
  else:
    return True, None

def chkconfig_services(client, hostname_list, state):
  try :
    if not state:
      raise Exception("No state passed")
    if state not in ['on', 'off']:
      raise Exception('Invalid state passed')
    #print "chkconfiging ctdb on GRIDCell %s."%','.join(hostname_list)
    r1 = client.cmd(hostname_list, 'cmd.run_all', ['chkconfig ctdb %s'%state], expr_form='list')
    if r1:
      for node, ret in r1.items():
        #print ret
        if ret["retcode"] != 0:
          errors = "Error chkconfiging CTDB on %s"%node
          raise Exception(errors)
    #print "chkconfiged ctdb on GRIDCell %s."%','.join(hostname_list)
    #print "chkconfiging winbind on GRIDCell %s."%','.join(hostname_list)
    r1 = client.cmd(hostname_list, 'cmd.run_all', ['chkconfig winbind %s'%state], expr_form='list')
    if r1:
      for node, ret in r1.items():
        #print ret
        if ret["retcode"] != 0:
          errors = "Error chkconfiging winbind on %s"%node
          raise Exception(errors)
    #print "chkconfiged winbind on GRIDCell %s."%','.join(hostname_list)
  except Exception, e:
    return False, 'Error chkconfig services : %s'%str(e)
  else:
    return True, None

def mount_admin_volume(client, hostname_list):
  try :
    admin_vol_name, err = common.get_admin_vol_name()
    if err:
      raise Exception(err)
    config_dir, err = common.get_config_dir()
    if err:
      raise Exception(err)
    #print "Mounting the IntegralStor Administration volume on GRIDCells %s."%','.join(hostname_list)
    r1 = client.cmd(hostname_list, 'cmd.run_all', ['mount -t glusterfs gridcell-pri.integralstor.lan:/%s %s'%(admin_vol_name, config_dir)], expr_form='list')
    #print r1
    if r1:
      for node, ret in r1.items():
        #print ret
        if ret["retcode"] != 0:
          print ret['retcode']
          errors = "GRIDCell %s"%node
          raise Exception(errors)
  except Exception, e:
    return False, 'Error mounting the admin volume : %s'%str(e)
  else:
    return True, None

def unmount_admin_volume(client, hostname_list):
  try :
    config_dir, err = common.get_config_dir()
    if err:
      raise Exception(err)
    #print "Unmounting the IntegralStor Administration volume on GRIDCells %s."%','.join(hostname_list)
    r1 = client.cmd(hostname_list, 'cmd.run_all', ['umount %s'%config_dir], expr_form='list')
    print r1
    if r1:
      for node, ret in r1.items():
        #print ret
        if ret["retcode"] != 0:
          errors = "GRIDCell : %s"%node
          raise Exception(errors)
  except Exception, e:
    return False, 'Error unmounting the admin volume : %s'%str(e)
  else:
    return True, None

def set_pool_status(client, hostname_list, part_of_pool):
  try :
    platform_root, err = common.get_platform_root()
    if err:
      raise Exception(err)
    if part_of_pool:
      cmd = 'touch %s/part_of_pool'%platform_root
    else:
      cmd = 'rm %s/part_of_pool'%platform_root

    r1 = client.cmd(hostname_list, 'cmd.run_all', [cmd], expr_form='list')
    #print r1
    if r1:
      for node, ret in r1.items():
        #print ret
        if ret["retcode"] not in [0, 1]:
          errors = "GRIDCell %s"%node
          raise Exception(errors)
  except Exception, e:
    return False, 'Error setting pool status : %s'%str(e)
  else:
    return True, None

def revert_add_node_to_storage(si, client, hostname, ip):

  # This is a revert so its a best effort 
  rc = -1
  try:
    error_list = []
    d, error = gluster_commands.remove_node_from_pool(si, hostname)
    if not d and error:
      error_list.append(error)
    rc, error = ctdb.remove_from_nodes_file(client, [ip])
    if not rc and error:
      error_list.append(error)
    if client:
      rc, error = set_pool_status(client, [hostname], False)
      if not rc  and error:
        error_list.append(error)
      rc, error = copy_appropriate_rc_local(client, [hostname], 'remove_from_grid')
      if not rc and error:
        error_list.append(error)
      rc, error = start_or_stop_services(client, [hostname], 'stop')
      if not rc and error:
        error_list.append(error)
      rc, error = chkconfig_services(client, [hostname], 'off')
      if not rc and error:
        error_list.append(error)
      rc, error = unlink_ctdb_files(client, [hostname])
      if not rc  and error:
        error_list.append(error)
      rc, error = unmount_admin_volume(client, [hostname])
      if not rc and error:
        error_list.append(error)
      if error_list:
        raise Exception(','.join(error_list))
  except Exception, e:
    return False, 'Error reverting GRIDCell addition : %s'%str(e)
  else:
    return True, None


def add_a_node_to_storage_pool(si, hostname):
  #hosts is a list of dicts with each dict containing the node name and the node info dict (from si)
  d = None
  try:
    ol = []
    error_list = []
    client = None
    ip = None

    if not si:
      raise Exception("Could not determine the configuration of the system!")
    if not hostname: 
      raise Exception("GRIDCell not found!")
    if hostname not in si:
      raise Exception("Could not determine the configuration of the GRIDCell!")

    try :
      ip = si[hostname]["interfaces"]["bond0"]["inet"][0]["address"]
    except Exception, e:
      pass

    if not ip:
      raise Exception("Could not determine the IP of the specified GRIDCell")


    localhost = socket.getfqdn().strip()
    if hostname.lower().strip() != localhost.lower().strip():
      #print 'adding node'
      d, err  = gluster_commands.add_a_node_to_pool(hostname)
      if err:
        error_list.append(err)
        rc1, err = revert_add_node_to_storage(si, client, hostname, ip)
        if err:
          error_list.append(err)
        raise Exception(','.join(error_list))
  
      rc, err = _regenerate_manifest_and_status(False)
      if not rc:
        error_list.append(err)
        rc1, err = revert_add_node_to_storage(si, client, hostname, ip)
        if err:
          error_list.append(err)
        raise Exception(','.join(error_list))
    
      client = salt.client.LocalClient()
      #print 'add ctdbnode'
      rc, err = ctdb.add_to_nodes_file(client, [ip])
      #print 'added ctdbnode'
      if not rc :
        error_list.append(err)
        rc1, err = revert_add_node_to_storage(si, client, hostname, ip)
        if err:
          error_list.append(err)
        raise Exception(','.join(error_list))
    
      #print '3'
      rc, error = mount_admin_volume(client, [hostname])
      #print '3'
      if not rc :
        error_list.append(error)
        rc1, err = revert_add_node_to_storage(si, client, hostname, ip)
        if err:
          error_list.append(err)
        raise Exception(','.join(error_list))
      
      #print '4'
      rc, error = link_ctdb_files(client, [hostname])
      print "Linked the CTDB nodes file on GRIDCell %s."%hostname
      #print '4'
      if not rc :
        error_list.append(error)
        rc1, err = revert_add_node_to_storage(si, client, hostname, ip)
        if err:
          error_list.append(err)
        raise Exception(','.join(error_list))
    
      #print '5'
      rc, error = chkconfig_services(client, [hostname], 'on')
      #print '5'
      if not rc :
        error_list.append(error)
        rc1, err = revert_add_node_to_storage(si, client, hostname, ip)
        if err:
          error_list.append(err)
        raise Exception(','.join(error_list))
  
      #print '6'
      rc, error = start_or_stop_services(client, [hostname], 'start')
      #print '6'
      if not rc :
        error_list.append(error)
        rc1, err = revert_add_node_to_storage(si, client, hostname, ip)
        if err:
          error_list.append(err)
        raise Exception(','.join(error_list))

      #print '7'
      rc, error = copy_appropriate_rc_local(client, hostname, 'add_to_grid')
      #print '7'
      if not rc :
        error_list.append(error)
        rc1, err = revert_add_node_to_storage(si, client, hostname, ip)
        if err:
          error_list.append(err)
        raise Exception(','.join(error_list))

      #print '8'
      rc, error = set_pool_status(client, [hostname], True)
      #print '8'
      if not rc :
        error_list.append(error)
        rc1, err = revert_add_node_to_storage(si, client, hostname, ip)
        if err:
          error_list.append(err)
        raise Exception(','.join(error_list))
  except Exception, e:
    return None, 'Error adding a GRIDCell to the storage pool : %s'%str(e)
  else:
    return d, None


def revert_remove_node_from_storage(si, client, hostname, ip):

  # This is a revert so its a best effort 
  try:
    error_list = []
    d, error = gluster_commands.add_a_node_to_pool(hostname)
    #print d
    #print error
    #print rc
    if error:
      error_list.append(error)
    rc, error = ctdb.add_to_nodes_file(client, [ip])
    if not rc  and error:
      error_list.append(error)
    if client:
      rc, error = mount_admin_volume(client, [hostname])
      if not rc  and error:
        error_list.append(error)
      rc, error = link_ctdb_files(client, [hostname])
      if not rc  and error:
        error_list.append(error)
      rc, error = chkconfig_services(client, [hostname], 'on')
      if not rc  and error:
        error_list.append(error)
      rc, error = start_or_stop_services(client, [hostname], 'start')
      if not rc and error:
        error_list.append(error)
      rc, error = copy_appropriate_rc_local(client, hostname, 'add_to_grid')
      if not rc  and error:
        error_list.append(error)
      rc, error = set_pool_status(client, [hostname], True)
      if not rc  and error:
        error_list.append(error)
    if error_list:
      raise Exception(','.join(error_list))
  except Exception, e:
    return False, 'Error reverting a GRIDCell removal from  the storage pool : %s'%str(e)
  else:
    return True, None


def remove_a_node_from_storage_pool(si, hostname):
  client = None
  ip = None
  error_list = []
  d = None
  try :
    try :
      ip = si[hostname]["interfaces"]["bond0"]["inet"][0]["address"]
    except Exception, e:
      pass
    client = salt.client.LocalClient()
    print '8'
    rc, error = set_pool_status(client, [hostname], False)
    print rc
    print error
    print '8'
    if not rc :
      error_list.append(error)
      rc1, err = revert_remove_node_from_storage(si, client, hostname, ip)
      if err:
        error_list.append(err)
      raise Exception(','.join(error_list))

    print '7'
    rc, error = copy_appropriate_rc_local(client, hostname, 'remove_from_grid')
    print '7'
    if not rc :
      error_list.append(error)
      rc1, err = revert_remove_node_from_storage(si, client, hostname, ip)
      if err:
        error_list.append(err)
      raise Exception(','.join(error_list))
    print '6'
    rc, error = start_or_stop_services(client, [hostname], 'stop')
    print '6'
    if not rc :
      error_list.append(error)
      rc1, err = revert_remove_node_from_storage(si, client, hostname, ip)
      if err:
        error_list.append(err)
      raise Exception(','.join(error_list))
    print '5'
    rc, error = chkconfig_services(client, [hostname], 'off')
    print '5'
    if not rc :
      error_list.append(error)
      rc1, err = revert_remove_node_from_storage(si, client, hostname, ip)
      if err:
        error_list.append(err)
      raise Exception(','.join(error_list))
    print '4'
    rc, error = unlink_ctdb_files(client, [hostname])
    print '4'
    if not rc :
      error_list.append(error)
      rc1, err = revert_remove_node_from_storage(si, client, hostname, ip)
      if err:
        error_list.append(err)
      raise Exception(','.join(error_list))
    print '3'
    rc, error = unmount_admin_volume(client, [hostname])
    print '3'
    if not rc :
      error_list.append(error)
      rc1, err = revert_remove_node_from_storage(si, client, hostname, ip)
      if err:
        error_list.append(err)
      raise Exception(','.join(error_list))
    print 'ctdbnode'
    rc, err = ctdb.remove_from_nodes_file(client, [ip])
    print 'ctdbnode'
    if not rc :
      error_list.append(err)
      rc1, err = revert_remove_node_from_storage(si, client, hostname, ip)
      if err:
        error_list.append(err)
      raise Exception(','.join(error_list))
    print 'removing node'
    d, err  = gluster_commands.remove_node_from_pool(si, hostname)
    print 'removing node'
    print d, err
    if not d:
      error_list.append(err)
      rc1, err = revert_remove_node_from_storage(si, client, hostname, ip)
      if err:
        error_list.append(err)
      raise Exception(','.join(error_list))
  except Exception, e:
    print str(e)
    return d, 'Error removing a GRIDCell from the storage pool : %s'%str(e)
  else:
    return d, None

def add_nodes_to_grid(remote_addr,pending_minions, first_time = False, accessing_from = 'primary', print_progress = False):

  success = []
  failed = []
  errors = ""
  try:
    accepted_failed_minions = []
    if pending_minions:
  
      ip = None
      sm_config, err = common.get_salt_master_config()
      if err:
        raise Exception(err)
      client = salt.client.LocalClient()
      opts = salt.config.master_config(sm_config)
      wheel = salt.wheel.Wheel(opts)
      print_progress = True
  
      if print_progress:
        print "Accepting the following GRIDCells : %s"%','.join(pending_minions)
      
      for m in pending_minions:
  
        ip = None
        if print_progress:
          print "Accepting GRIDCell %s"%m
        rc, err = accept_salt_key(wheel, m)
        if not rc :
          if print_progress:
            print "Failed to add %s to salt : %s"%(m, err)
          errors += "Failed to add %s to salt : %s"%(m, err)
          failed.append(m)
          continue
        if print_progress:
          print "Accepted GRIDCell %s"%m
  
      if print_progress:
        print "Pausing 30 seconds to salt accept"
      time.sleep(30)
      for m in pending_minions:
        ip, err = get_minion_ip(client, m)
        if print_progress and err:
          print "Error retrieving the IP from GRIDCell %s : %s"%(m, err)
        if not ip:
          if print_progress:
            print  "Error retrieving the IP from GRIDCell %s : %s"%(m, err)
          accepted_failed_minions.append(m)
          errors += "Error retrieving the IP from GRIDCell %s : %s"%(m, err)
          #Cannot add to DNS so remove from salt as well
          failed.append(m)
          continue
        else:
          if print_progress:
            print "Found Bond IP : %s for GRIDCell %s"%(ip, m)
  
        if print_progress:
          print 'Adding GRIDCell %s to DNS'%m
        rc, err = add_to_dns(client, m, ip)
        if err and print_progress:
          print 'Error adding GRIDCell %s to DNS : %s'%(m, err)
        if not rc :
          accepted_failed_minions.append(m)
          errors += err
          failed.append(m)
          continue
        else:
          if print_progress:
            print "Added %s to DNS"%m
  
  
        #All went well so audit and continue to the next
        print "Successfully added GRIDCell %s to the grid"%m
  
        if not first_time:
          ret, err = audit.audit("hardware_scan_node_added", "Added a new GRIDCell %s to the grid"%m,remote_addr )
          if err:
            errors += err
        success.append(m)
  
      #Some failed so kick off minion restart and then delete their keys
      if accepted_failed_minions:
        ret, err = restart_minions(client, accepted_failed_minions)
        if err:
          errors += err
        for m in accepted_failed_minions:
          r, err = delete_salt_key(m)
          if (not r) and err:
            errors += err
  
      if success:
        if print_progress:
          print "Syncing modules to GRIDCells"
        rc, err = sync_salt_modules(client, success)
        if err:
          raise Exception(err)
        if print_progress:
          print "Syncing modules to GRIDCells.. Done."
          print
  
        #print "Successfully added : %s"%success
        #print "Failed adding : %s"%failed
  
        if print_progress:
          print "Regenerating manifest and status"
  
        rc, err = _regenerate_manifest_and_status(first_time)
        if not rc  :
          if err:
            errors += err
          else:
            errors += 'Error regenerating manifest and status'
        else:
          if print_progress:
            print "Regenerated manifest and status"
      if errors:
        raise Exception(errors)
  except Exception, e:
    if errors:
      err = errors + ' ' + str(e)
    else:
      err = str(e)
    return (success, failed), 'Error adding GRIDCells to the grid : %s'%err
  else:
    return (success, failed), None

  
def main():
  #_regenerate_manifest_and_status(True)
  #add_nodes_to_grid("1.1.1.1",['a', 'b'], first_time = False, accessing_from = 'primary')
  pass

if __name__ == "__main__":
  main()

'''
      if wheel.call_func('key.accept', match=('%s'%m)):
	      time.sleep(20)
        command_to = 'salt %s saltutil.sync_all'%(m)
        ret, ret_code = command.execute_with_rc(command_to)
        #print ret, ret_code
        time.sleep(20)
        r = client.cmd(m, 'grains.item', ['ip_interfaces'], timeout=180)
        #print r
        if r:
          #print r[m]
          #print r[m]['ip_interfaces']
          #print r[m]['ip_interfaces']['bond0']
          if 'ip_interfaces' in r[m] and r[m]['ip_interfaces']['bond0']:
            ip = r[m]['ip_interfaces']['bond0'][0]
            print "Found Bond IP : %s"%ip
          else:
            print "Could not find the Bond IP"
        if ip:
          print "Adding %s to DNS"%m
          r1 = client.cmd('roles:primary', 'ddns.add_host', ['integralstor.lan', m, 86400, ip], expr_form='grain', timeout=180)
          print "Added %s to DNS"%m
          if not r1:
            errors = "Error adding the DNS information for GRIDCell %s"%m
            print "Error adding DNS information for GRIDCell %s"%m
          else:
            audit.audit("hardware_scan_node_added", "Added a new GRIDCell %s to the grid"%m,remote_addr )
            success.append(m)
        else:
            errors = "Error adding the DNS information for %s. No IP address information found."%m
            print "Error retrieving the IP from GRIDCell %s"%m
      else:
        failed.append(m)
    #print "Successfully added : %s"%success
    #print "Failed adding : %s"%failed
    print "Regenerating manifest and status"
    rc, err = _regenerate_manifest_and_status(first_time)
    print "Regenerated manifest and status"
    if not rc :
      if errors:
        errors += "Error regenerating the new configuration : "
      else:
        errors = "Error regenerating the new configuration : "
      errors += ",".join(command.get_output_list(ret))
      errors += ",".join(command.get_error_list(ret))
'''
