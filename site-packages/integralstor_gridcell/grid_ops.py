"""Operations pertaining to setting up the grid - initial setup, salt, DNS, CTDB, etc..

This exports:
  _regenerate_manifest_and_status - Regenerates the manifest and status files.
  get_accepted_minions - Gets the list of accepted salt minions.
  get_pending_minions - Gets the list of pending salt minions.
  restart_minions - Restart the specified minions.
  accept_salt_key - Accepts the salt key of the specified gridcell.
  delete_salt_key - Deletes the salt key for the specified gridcell.
  sync_salt_modules - Sync all salt modules with the specified minions.
  get_minion_ip - Gets the bond0 IP of the specified salt minion.
  link_ctdb_files - Creates a soft link of the CTDB files to the admin vol lock directory.
  unlink_ctdb_files - Removes the soft links of the CTDB files to the admin vol lock directory.
  copy_appropriate_rc_local - Depending on whether primary/secondary or normal, it copies the appropriate rc.local files.
  start_or_stop_services - Starts or stops the set of services on the specified gridcells.
  chkconfig_services - Ensures that a set of services start at boot on the specified gridcells.
  mount_admin_volume - Mounts the admin volume on the specified gridcells.
  unmount_admin_volume - Unmounts the admin volume on the specified gridcells.
  set_pool_status - Either touches or removes a file to denote if the gridcell is part of the pool or not.
  add_a_gridcell_to_storage_pool - Performs a set of operations using other grid_ops functions to get a gridcell into the storage pool.
  revert_add_a_gridcell_to_storage_pool - Reverts the process of getting a gridcell into the storage pool.
  remove_a_gridcell_from_storage_pool - Performs a bunch of operations using other gridops functions to remove a gridcell from the storage pool.
  revert_remove_a_gridcell_from_storage_pool - Performs a bunch of operations using other gridops functions to revert the removal of a gridcell from the storage pool.
  add_gridcells_to_grid - Performa a bunch of operations to add a set of gridcells to the grid..

"""
import salt.client, salt.wheel

import socket, time

from integralstor_common import command, audit, common
from integralstor_gridcell import ctdb, gluster_trusted_pools, dns

def _regenerate_manifest_and_status(first_time = False):
  """(Re)generates the manifest and status file.

  Return True if successful and False if not.

  first_time - Tells us if this is being called from the first time setup when we need to store a tmp path to store the files. Else in the integralview admin vol's config dir.
  """

  rc = -1
  try:
    if first_time:
      ss_path, err = common.get_tmp_path()
      if err:
        raise Exception(err)
    else:
      ss_path, err = common.get_system_status_path()
      if err:
        raise Exception(err)

    #Path to the gridcell scripts
    scripts_path, err = common.get_python_scripts_path()
    if err:
      raise Exception(err)

    #Path to the common scripts
    common_python_scripts_path, err = common.get_common_python_scripts_path()
    if err:
      raise Exception(err)

    ret, err = command.get_command_output("python %s/generate_manifest.py %s"%(common_python_scripts_path, ss_path))
    if err:
      raise Exception(err)

    ret, err = command.get_command_output("python %s/generate_status.py %s"%(common_python_scripts_path, ss_path))
    if err:
      raise Exception(err)

  except Exception, e:
    return False, 'Error regenerating the new configuration : %s'%str(e)
  else:
    return True, None


def get_accepted_minions():
  """Get the list of accepted salt minions."""

  minion_list = []
  try :

    #Get the location of the salt master config file.
    cfg, err = common.get_salt_master_config()
    if err:
      raise Exception(err)

    opts = salt.config.master_config(cfg)
    wheel = salt.wheel.Wheel(opts)
    keys = wheel.call_func('key.list_all')
    if keys:
      minion_list = keys['minions']

  except Exception, e:
    return None, "Error retrieving accepted minions : %s"%str(e)
  else:
    return minion_list, None

def get_pending_minions():
  """Get the list of pending salt minions."""
  pending_minions = None
  try:

    #Get the location of the salt master config file.
    cfg, err = common.get_salt_master_config()
    if err:
      raise Exception(err)

    opts = salt.config.master_config(cfg)
    wheel = salt.wheel.Wheel(opts)
    keys = wheel.call_func('key.list_all')
    if keys:
      pending_minions = keys['minions_pre']
  except Exception, e:
    return None, 'Error retrieving pending minions : %s'%str(e)
  else:
    return pending_minions, None

def restart_minions(client, minion_list):
  """Restart the salt minion in the specified nodes.

  client - The salt client handle
  minion_list - The list of nodes on which this is to be done.
  """

  try:
    r1 = client.cmd(minion_list, 'cmd.run', ['echo service salt-minion restart | at now + 1 minute'], expr_form='list')
  except Exception, e:
    return False, 'Error restarting minions : %s'%str(e)
  else:
    return True, None

def accept_salt_key(wheel, m):
  """Accept the specified host into salt..

  wheel - salt's wheel handle.
  m - the host to accept.
  """
  ret = -1
  try:
    if not wheel or not m:
      raise Exception('Required parameters not passed')
    if not wheel.call_func('key.accept', match=('%s'%m)):
      raise Exception('GRIDCell %s'%m)
    else:
      ret = 0
  except Exception, e:
    return False, 'Error accepting GRIDCell key : %s'%str(e)
  else:
    return True, None

def delete_salt_key(hostname):
  """Delete the salt minion key of the specified hostname this excommunicating it from the salt master's purview.

  hostname - the host to accept.
  """

  try:
    #Get the location of the salt master config file.
    cfg, err = common.get_salt_master_config()
    if err:
      raise Exception(err)

    opts = salt.config.master_config(cfg)
    wheel = salt.wheel.Wheel(opts)
    keys = wheel.call_func('key.list_all')

    #First check if it is currently part of the master's keys.
    if (not keys) or ('minions' not in keys) or (hostname not in keys['minions']):
      raise Exception("Specified GRIDCell is not part of the grid")

    wheel.call_func('key.delete', match=(hostname))

  except Exception, e:
    errors = "Error removing GRIDCell key from the grid : %s"%str(e)
    return False, errors
  else:
    return True, None

def sync_salt_modules(client, minion_list):
  """Sync the salt modules onto the specified minions.

  client - the salt client handle.
  minion_list - the list of hostnames onto which the modules need to be synced.
  """

  try:
    rc = client.cmd(minion_list, 'saltutil.sync_modules', expr_form='list')
  except Exception, e:
    return False, 'Error syncing salt modules : %s'%str(e)
  else:
    return True, None

def get_minion_ip(client, m):
  """Get the IP address assigned to the bond0 interface for the specified host.

  client - the salt client handle.
  m - the hostname for which the IP address is desired.
  """
  ip = None
  try:
    r = client.cmd(m, 'grains.item', ['ip_interfaces'])
    #print r
    if r:
      if 'ip_interfaces' in r[m] and r[m]['ip_interfaces']['bond0']:
        ip = r[m]['ip_interfaces']['bond0'][0]
      else:
        raise Exception("The IP address for bond0 in GRIDCell %s does not seem to have been configured."%m)
    else:
      raise Exception("Could not retrieve the IP for GRIDCell %s."%m)
  except Exception, e:
    return None, 'Error retrieving minion IP address : %s'%str(e)
  else:
    return ip, None

def link_ctdb_files(client, hostname_list):
  """Soft link the default CTDB ctdb and the nodes config files to files in the integralview admin vol so they can be mounted and remain consistent across all nodes. This operation is performed on the specified set of nodes.

  client - salt's client handle.
  hostname_list - The list of nodes on which to perform this operation.
  """
  try :
    #Get the admin vol's config dir.
    config_dir, err = common.get_config_dir()
    if err:
      raise Exception(err)

    #print "Removing original CTDB config file on GRIDCell %s."%','.join(hostname_list)
    r1 = client.cmd(hostname_list, 'cmd.run_all', ['rm /etc/sysconfig/ctdb'], expr_form='list')
    #print "Removed original CTDB config file on GRIDCell %s."%','.join(hostname_list)

    #print "Linking the CTDB config file on GRIDCell %s."%','.join(hostname_list)
    r1 = client.cmd(hostname_list, 'cmd.run_all', ['ln -s %s/lock/ctdb /etc/sysconfig/ctdb'%config_dir], expr_form='list')
    if r1:
      for node, ret in r1.items():
        #print ret
        if ret["retcode"] != 0:
          errors = 'Error linking ctdb config file on GRIDCell %s'%node
          raise Exception(errors)
    #print "Linked the CTDB config file on GRIDCell %s."%','.join(hostname_list)

    #print "Removing original CTDB nodes file on GRIDCell %s."%','.join(hostname_list)
    r1 = client.cmd(hostname_list, 'cmd.run_all', ['rm /etc/ctdb/nodes'], expr_form='list')
    #print "Removed original CTDB nodes file on GRIDCell %s."%','.join(hostname_list)

    #print "Linking the CTDB nodes file on GRIDCell %s."%','.join(hostname_list)
    r1 = client.cmd(hostname_list, 'cmd.run_all', ['ln -s %s/lock/nodes /etc/ctdb/nodes'%config_dir], expr_form='list')
    if r1:
      for node, ret in r1.items():
        #print ret
        if ret["retcode"] != 0:
          errors = "Error linking the CTDB nodes file on GRIDCell %s"%node
          #Undo the previous linking
          r1 = client.cmd(hostname_list, 'cmd.run_all', ['rm /etc/sysconfig/ctdb'], expr_form='list')
          raise Exception(errors)

  except Exception, e:
    error_str = str(e)
    return False, error_str
  else:
    return True, None

def unlink_ctdb_files(client, hostname_list):
  """Removes the soft link on the default CTDB ctdb and the nodes config files to files in the integralview admin vol so they can be mounted and remain consistent across all nodes. This operation is performed on the specified set of nodes.

  client - salt's client handle.
  hostname_list - The list of nodes on which to perform this operation.
  """
  try :
    r1 = client.cmd(hostname_list, 'cmd.run_all', ['rm /etc/sysconfig/ctdb'], expr_form='list')
    r1 = client.cmd(hostname_list, 'cmd.run_all', ['rm /etc/ctdb/nodes'], expr_form='list')
  except Exception, e:
    err = "Error removing CTDB files : %s"%str(e)
    return False, err
  else:
    return True, None

def copy_appropriate_rc_local(client, hostname_list, action):
  try :
    defaults_dir, err = common.get_defaults_dir()
    if err:
      raise Exception(err)
    if not action:
      raise Exception('No action specified')
    if action not in ['add_to_grid', 'remove_from_grid']:
      raise Exception('Invalied action specified')
    if action == 'add_to_grid':
      cmd = 'cp %s/rc_local/normal/rc.local.in_cluster /etc/rc.local'%defaults_dir
    else:
      cmd = 'cp %s/rc_local/normal/rc.local.not_in_cluster /etc/rc.local'%defaults_dir
    #print cmd
    r1 = client.cmd(hostname_list, 'cmd.run_all', [cmd], expr_form='list')
    #print r1
    if r1:
      for node, ret in r1.items():
        #print ret
        if ret["retcode"] != 0:
          errors = "Error copying on GRIDCell %s"%node
          raise Exception(errors)
    cmd = 'chmod 755 /etc/rc.local'
    r1 = client.cmd(hostname_list, 'cmd.run_all', [cmd], expr_form='list')
    #print r1
    if r1:
      for node, ret in r1.items():
        #print ret
        if ret["retcode"] != 0:
          errors = "Error changing permissions on GRIDCell %s"%node
          raise Exception(errors)
  except Exception, e:
    return False, 'Error placing rc.local : %s'%str(e)
  else:
    return True, None

def start_or_stop_services(client, hostname_list, action):
  """Start or stop ctdb and winbind services in the specified nodes.

  client - salt's client handle.
  hostname_list - The list of nodes on which to perform this operation.
  action - either 'start' or 'stop'.
  """
  try :
    if not action:
      raise Exception('No action specified')
    if action not in ['start', 'stop']:
      raise Exception('Invalied action specified')

    #print "%sing ctdb on GRIDCell %s."%(action, ','.join(hostname_list))
    r1 = client.cmd(hostname_list, 'cmd.run_all', ['service ctdb %s'%action], expr_form='list')
    #print r1
    if r1:
      for node, ret in r1.items():
        #print ret
        if ret["retcode"] != 0:
          errors = "Error %sing CTDB on %s"%(action, node)
          raise Exception(errors)
    #print "%sed ctdb on GRIDCell %s."%(action, ','.join(hostname_list))

    #print "%sing winbind on GRIDCell %s."%(action, ','.join(hostname_list))
    r1 = client.cmd(hostname_list, 'cmd.run_all', ['service winbind %s'%action], expr_form='list')
    #print r1
    if r1:
      for node, ret in r1.items():
        #print ret
        if ret["retcode"] != 0:
          errors = "Error %sing winbind on %s"%(action, node)
          raise Exception(errors)
    #print "%sed winbind on GRIDCell %s."%(action, ','.join(hostname_list))

  except Exception, e:
    return False, 'Error starting/stopping service : %s'%str(e)
  else:
    return True, None

def chkconfig_services(client, hostname_list, state):
  """Run a chkconfig on ctdb and winbind on the specified nodes.

  client - salt's client handle.
  hostname_list - The list of nodes on which to perform this operation.
  state - either 'on' or 'off'.
  """
  try :
    if not state:
      raise Exception("No state passed")
    if state not in ['on', 'off']:
      raise Exception('Invalid state passed')

    #print "chkconfiging ctdb on GRIDCell %s."%','.join(hostname_list)
    r1 = client.cmd(hostname_list, 'cmd.run_all', ['chkconfig ctdb %s'%state], expr_form='list')
    if r1:
      for node, ret in r1.items():
        #print ret
        if ret["retcode"] != 0:
          errors = "Error chkconfiging CTDB on %s"%node
          raise Exception(errors)
    #print "chkconfiged ctdb on GRIDCell %s."%','.join(hostname_list)

    #print "chkconfiging winbind on GRIDCell %s."%','.join(hostname_list)
    r1 = client.cmd(hostname_list, 'cmd.run_all', ['chkconfig winbind %s'%state], expr_form='list')
    if r1:
      for node, ret in r1.items():
        #print ret
        if ret["retcode"] != 0:
          errors = "Error chkconfiging winbind on %s"%node
          raise Exception(errors)
    #print "chkconfiged winbind on GRIDCell %s."%','.join(hostname_list)

  except Exception, e:
    return False, 'Error chkconfig services : %s'%str(e)
  else:
    return True, None

def mount_admin_volume(client, hostname_list):
  """Mount the gluster admin vol in the default config dir location on the specified nodes.

  client - salt's client handle.
  hostname_list - The list of nodes on which to perform this operation.
  """
  try :
    #Get the name of the admin vol.
    admin_vol_name, err = common.get_admin_vol_name()
    if err:
      raise Exception(err)

    #Get the config dir - the mount point.
    config_dir, err = common.get_config_dir()
    if err:
      raise Exception(err)

    #print "Mounting the IntegralStor Administration volume on GRIDCells %s."%','.join(hostname_list)
    r1 = client.cmd(hostname_list, 'cmd.run_all', ['mount -t glusterfs gridcell-pri.integralstor.lan:/%s %s'%(admin_vol_name, config_dir)], expr_form='list')
    #print r1
    if r1:
      for node, ret in r1.items():
        #print ret
        if ret["retcode"] != 0:
          #print ret['retcode']
          errors = "GRIDCell %s"%node
          raise Exception(errors)
  except Exception, e:
    return False, 'Error mounting the admin volume on: %s'%str(e)
  else:
    return True, None

def unmount_admin_volume(client, hostname_list):
  """Unmount the gluster admin vol on the specified nodes.

  client - salt's client handle.
  hostname_list - The list of nodes on which to perform this operation.
  """
  try :
    #Get the config dir - the mount point.
    config_dir, err = common.get_config_dir()
    if err:
      raise Exception(err)

    #print "Unmounting the IntegralStor Administration volume on GRIDCells %s."%','.join(hostname_list)
    r1 = client.cmd(hostname_list, 'cmd.run_all', ['umount %s'%config_dir], expr_form='list')
    print r1
    if r1:
      for node, ret in r1.items():
        #print ret
        if ret["retcode"] != 0:
          errors = "GRIDCell : %s"%node
          raise Exception(errors)
  except Exception, e:
    return False, 'Error unmounting the admin volume on : %s'%str(e)
  else:
    return True, None

def add_a_gridcell_to_storage_pool(si, hostname):
  """Performs all necessary oprations required to add a node to the gluster storage pool. In addition to the actual gluster operation, we need to make sure all the other anciliary operations are also performed.

  si - The system info dict needed to pull in all the required info.
  hostname - The hostname of the node to be added.
  """
  return_dict = None
  try:
    error_list = []
    client = None
    ip = None

    if not si:
      raise Exception("Could not determine the configuration of the system!")
    if not hostname: 
      raise Exception("GRIDCell not found!")
    if hostname not in si:
      raise Exception("Could not determine the configuration of the GRIDCell!")

    #Get the bond IP or the hostname
    try :
      ip = si[hostname]["interfaces"]["bond0"]["inet"][0]["address"]
    except Exception, e:
      pass
    if not ip:
      raise Exception("Could not determine the IP of the specified GRIDCell")

    localhost = socket.getfqdn().strip()
    if hostname.lower().strip() == localhost.lower().strip():
      raise Exception('Cannot add the local host to the storage pool.')

    #Now finally good to go ahead and try..
    client = salt.client.LocalClient()

    #print 'Stopping services.'
    rc, error = start_or_stop_services(client, [hostname], 'stop')
    if not rc :
      error_list.append(error)
      rc1, err = revert_add_a_gridcell_to_storage_pool(si, client, hostname, ip)
      if err:
        error_list.append(err)
      raise Exception(','.join(error_list))
    #print 'Stopped services.'

    #print 'adding to the gluster storage pool.'
    return_dict, err  = gluster_trusted_pools.add_a_gridcell_to_gluster_pool(hostname)
    if err:
      error_list.append(err)
      rc1, err = revert_add_a_gridcell_to_storage(si, client, hostname, ip)
      if err:
        error_list.append(err)
      raise Exception(','.join(error_list))
    #print 'added to the gluster storage pool.'
  
    '''
    #print 'regenerating manifest and status.'
    rc, err = _regenerate_manifest_and_status(False)
    if not rc:
      error_list.append(err)
      rc1, err = revert_add_a_gridcell_to_storage_pool(si, client, hostname, ip)
      if err:
        error_list.append(err)
      raise Exception(','.join(error_list))
    #print 'regenerated manifest and status.'
    '''
  
    #print 'adding to ctdb nodes file.'
    rc, err = ctdb.add_to_nodes_file(client, [ip])
    #print 'added ctdbnode'
    if not rc :
      error_list.append(err)
      rc1, err = revert_add_a_gridcell_to_storage_pool(si, client, hostname, ip)
      if err:
        error_list.append(err)
      raise Exception(','.join(error_list))
    #print 'added to ctdb nodes file.'
  
    #print 'Mounting admin volume.'
    rc, error = mount_admin_volume(client, [hostname])
    if not rc :
      error_list.append(error)
      rc1, err = revert_add_a_gridcell_to_storage_pool(si, client, hostname, ip)
      if err:
        error_list.append(err)
      raise Exception(','.join(error_list))
    #print 'Mounted admin volume.'
    
    #print 'Linking CTDB files.'
    rc, error = link_ctdb_files(client, [hostname])
    print "Linked the CTDB nodes file on GRIDCell %s."%hostname
    if not rc :
      error_list.append(error)
      rc1, err = revert_add_a_gridcell_to_storage_pool(si, client, hostname, ip)
      if err:
        error_list.append(err)
      raise Exception(','.join(error_list))
    #print 'Linked CTDB files.'
    
    #print 'Chkconfiging services.'
    rc, error = chkconfig_services(client, [hostname], 'on')
    if not rc :
      error_list.append(error)
      rc1, err = revert_add_a_gridcell_to_storage_pool(si, client, hostname, ip)
      if err:
        error_list.append(err)
      raise Exception(','.join(error_list))
    #print 'Chkconfiged services.'

    #print 'Starting services.'
    rc, error = start_or_stop_services(client, [hostname], 'start')
    if not rc :
      error_list.append(error)
      rc1, err = revert_add_a_gridcell_to_storage_pool(si, client, hostname, ip)
      if err:
        error_list.append(err)
      raise Exception(','.join(error_list))
    #print 'Started services.'

    #print 'copying rc.local files.'
    rc, error = copy_appropriate_rc_local(client, hostname, 'add_to_grid')
    if not rc :
      error_list.append(error)
      rc1, err = revert_add_a_gridcell_to_storage_pool(si, client, hostname, ip)
      if err:
        error_list.append(err)
      raise Exception(','.join(error_list))
    #print 'copyed rc.local files.'

    #print 'Reloading CTDB nodes files.'
    rc, err = ctdb.reload_nodes_file(client, [ip])
    if not rc :
      error_list.append(err)
      rc1, err = revert_add_a_gridcell_to_storage_pool(si, client, hostname, ip)
      if err:
        error_list.append(err)
      raise Exception(','.join(error_list))
    #print 'reloaded  ctdb nodes file.'

    '''
    #Does not seem to be needed so commenting it out for now.
    #print '8'
    rc, error = set_pool_status(client, [hostname], True)
    #print '8'
    if not rc :
      error_list.append(error)
      rc1, err = revert_add_a_gridcell_to_storage_pool(si, client, hostname, ip)
      if err:
        error_list.append(err)
      raise Exception(','.join(error_list))
    '''
  except Exception, e:
    return None, 'Error adding a GRIDCell to the storage pool : %s'%str(e)
  else:
    return return_dict, None


def revert_add_a_gridcell_to_storage_pool(si, client, hostname, ip):
  """Performs all necessary oprations required to revert the add a node to the gluster storage pool process in case of it failing. 

  si - The system info dict needed to pull in all the required info.
  hostname - The hostname of the node to be added.
  client - salt's client handle.
  ip - The bond IP of the node so we dont have to find it again.
  """

  # This is a revert so its a best effort 
  rc = -1
  try:
    error_list = []
    d, error = gluster_trusted_pools.remove_a_gridcell_from_gluster_pool(hostname)
    if not d and error:
      error_list.append(error)

    rc, error = ctdb.remove_from_nodes_file(client, [ip])
    if not rc and error:
      error_list.append(error)

    if client:
      '''
      #Possibly not needed now.
      rc, error = set_pool_status(client, [hostname], False)
      if not rc  and error:
        error_list.append(error)
      '''

      rc, error = copy_appropriate_rc_local(client, [hostname], 'remove_from_grid')
      if not rc and error:
        error_list.append(error)

      rc, error = start_or_stop_services(client, [hostname], 'stop')
      if not rc and error:
        error_list.append(error)

      rc, error = chkconfig_services(client, [hostname], 'off')
      if not rc and error:
        error_list.append(error)

      rc, error = unlink_ctdb_files(client, [hostname])
      if not rc  and error:
        error_list.append(error)

      rc, error = unmount_admin_volume(client, [hostname])
      if not rc and error:
        error_list.append(error)

      if error_list:
        raise Exception(','.join(error_list))
  except Exception, e:
    return False, 'Error reverting GRIDCell addition : %s'%str(e)
  else:
    return True, None


def remove_a_gridcell_from_storage_pool(si, hostname):
  """Performs all necessary oprations required to remove a node from the gluster storage pool. In addition to the actual gluster operation, we need to make sure all the other anciliary operations are also performed.

  si - The system info dict needed to pull in all the required info.
  hostname - The hostname of the node to be removed.
  """
  return_dict = None
  try :
    client = None
    ip = None
    error_list = []
    try :
      ip = si[hostname]["interfaces"]["bond0"]["inet"][0]["address"]
    except Exception, e:
      pass

    client = salt.client.LocalClient()
    '''
    #Possibly not needed now
    rc, error = set_pool_status(client, [hostname], False)
    if not rc :
      error_list.append(error)
      rc1, err = revert_remove_a_gridcell_from_storage_pool(si, client, hostname, ip)
      if err:
        error_list.append(err)
      raise Exception(','.join(error_list))
    '''

    #print 'Copying appropriate rc_local files'
    rc, error = copy_appropriate_rc_local(client, hostname, 'remove_from_grid')
    if not rc :
      error_list.append(error)
      rc1, err = revert_remove_a_gridcell_from_storage_pool(si, client, hostname, ip)
      if err:
        error_list.append(err)
      raise Exception(','.join(error_list))
    #print 'Copyed appropriate rc_local files'

    print 'Stopping services'
    rc, error = start_or_stop_services(client, [hostname], 'stop')
    if not rc :
      error_list.append(error)
      rc1, err = revert_remove_a_gridcell_from_storage_pool(si, client, hostname, ip)
      if err:
        error_list.append(err)
      raise Exception(','.join(error_list))
    print 'Stopped services'

    print 'Chkconfiging services off'
    rc, error = chkconfig_services(client, [hostname], 'off')
    if not rc :
      error_list.append(error)
      rc1, err = revert_remove_a_gridcell_from_storage_pool(si, client, hostname, ip)
      if err:
        error_list.append(err)
      raise Exception(','.join(error_list))
    print 'Chkconfiged services off'

    print 'Unlinking ctdb files'
    rc, error = unlink_ctdb_files(client, [hostname])
    if not rc :
      error_list.append(error)
      rc1, err = revert_remove_a_gridcell_from_storage_pool(si, client, hostname, ip)
      if err:
        error_list.append(err)
      raise Exception(','.join(error_list))
    print 'Unlinked ctdb files'

    print 'Unmounting admin vol'
    rc, error = unmount_admin_volume(client, [hostname])
    if not rc :
      error_list.append(error)
      rc1, err = revert_remove_a_gridcell_from_storage_pool(si, client, hostname, ip)
      if err:
        error_list.append(err)
      raise Exception(','.join(error_list))
    print 'Unmounted admin vol'

    print 'Removing from ctdb modes file'
    rc, err = ctdb.remove_from_nodes_file(client, [ip])
    if not rc :
      error_list.append(err)
      rc1, err = revert_remove_a_gridcell_from_storage_pool(si, client, hostname, ip)
      if err:
        error_list.append(err)
      raise Exception(','.join(error_list))
    print 'Removed from ctdb modes file'

    print 'Removing from the gluster pool'
    return_dict, err  = gluster_trusted_pools.remove_a_gridcell_from_gluster_pool(si, hostname)
    if not d:
      error_list.append(err)
      rc1, err = revert_remove_a_gridcell_from_storage_pool(si, client, hostname, ip)
      if err:
        error_list.append(err)
      raise Exception(','.join(error_list))
    print 'Removed from the gluster pool'

  except Exception, e:
    print str(e)
    return d, 'Error removing a GRIDCell from the storage pool : %s'%str(e)
  else:
    return d, None

def revert_remove_a_gridcell_from_storage_pool(si, client, hostname, ip):
  """Performs all necessary oprations required to revert the remove a node to the gluster storage pool process in case of it failing. 

  si - The system info dict needed to pull in all the required info.
  hostname - The hostname of the node to be added.
  client - salt's client handle.
  ip - The bond IP of the node so we dont have to find it again.
  """

  # This is a revert so its a best effort 
  try:
    error_list = []

    d, error = gluster_trusted_pools.add_a_gridcell_to_gluster_pool(hostname)
    if error:
      error_list.append(error)

    rc, error = ctdb.add_to_nodes_file(client, [ip])
    if not rc  and error:
      error_list.append(error)

    if client:
      rc, error = mount_admin_volume(client, [hostname])
      if not rc  and error:
        error_list.append(error)

      rc, error = link_ctdb_files(client, [hostname])
      if not rc  and error:
        error_list.append(error)

      rc, error = chkconfig_services(client, [hostname], 'on')
      if not rc  and error:
        error_list.append(error)

      rc, error = start_or_stop_services(client, [hostname], 'start')
      if not rc and error:
        error_list.append(error)

      rc, error = copy_appropriate_rc_local(client, hostname, 'add_to_grid')
      if not rc  and error:
        error_list.append(error)

      rc, error = set_pool_status(client, [hostname], True)
      if not rc  and error:
        error_list.append(error)

    if error_list:
      raise Exception(','.join(error_list))
  except Exception, e:
    return False, 'Error reverting a GRIDCell removal from  the storage pool : %s'%str(e)
  else:
    return True, None

def add_gridcells_to_grid(request_meta,pending_minions, first_time = False, accessing_from = 'primary', print_progress = False):
  """Add the specified set of gridcells to the salt masters and to DNS and sync our salt modules with them.

  remote_addr - The address of the integralview admin's browser for audit purposes..
  pending_minions - The set of pending salt minions to be accepted
  first_time - Is this being called from the first time setup or not?
  accessing_from - Are we being accessed from the primary or not?
  print_progress - Shd we print progress messages onto the console?
  """

  successful_gridcells = []
  failed_gridcells = []
  errors = ""
  try:
    #The list of minions that got accepted but some following operations failed after that.
    accepted_failed_minions = []

    if pending_minions:
      ip = None

      #Get the location of the salt master config file.
      sm_config, err = common.get_salt_master_config()
      if err:
        raise Exception(err)

      #Get the salt handles
      client = salt.client.LocalClient()
      opts = salt.config.master_config(sm_config)
      wheel = salt.wheel.Wheel(opts)

      #Should we print the progress on the console or not?
      if print_progress:
        print "Accepting the following GRIDCells : %s"%','.join(pending_minions)
      
      for m in pending_minions:
  
        ip = None

        if print_progress:
          print "Accepting GRIDCell %s"%m
        rc, err = accept_salt_key(wheel, m)
        if not rc :
          if print_progress:
            print "Failed to add %s to salt : %s"%(m, err)
          errors += "Failed to add %s to salt : %s"%(m, err)
          failed_gridcells.append(m)
          continue
        if print_progress:
          print "Accepted GRIDCell %s"%m
  
      #Now pause so that the accept actually gets reflected on the minion side.
      if print_progress:
        print "Pausing 30 seconds to salt accept"
      time.sleep(30)

      for m in pending_minions:

        #Get the bond IP for each of the minions.
        ip, err = get_minion_ip(client, m)
        if print_progress and err:
          print "Error retrieving the IP from GRIDCell %s : %s"%(m, err)
        if not ip:
          if print_progress:
            print  "Error retrieving the IP from GRIDCell %s : %s"%(m, err)
          accepted_failed_minions.append(m)
          errors += "Error retrieving the IP from GRIDCell %s : %s"%(m, err)
          #Cannot add to DNS so remove from salt as well
          failed_gridcells.append(m)
          continue
        else:
          if print_progress:
            print "Found Bond IP : %s for GRIDCell %s"%(ip, m)
  
        #Accepted into salt and found the IP so now add to DNS.
        if print_progress:
          print 'Adding GRIDCell %s to DNS'%m
        rc, err = dns.add_to_dns(client, m, ip)
        if err and print_progress:
          print 'Error adding GRIDCell %s to DNS : %s'%(m, err)
        if not rc :
          accepted_failed_minions.append(m)
          errors += err
          failed_gridcells.append(m)
          continue
        else:
          if print_progress:
            print "Added %s to DNS"%m
  
        #All went well so audit and continue to the next
        if print_progress:
          print "Successfully added GRIDCell %s to the grid"%m
  
        #If it is part of the first time setup, then dont audit..
        if not first_time:
          ret, err = audit.audit("hardware_scan_node_added", "Added a new GRIDCell %s to the grid"%m,request_meta )
          if err:
            errors += err
        successful_gridcells.append(m)
  
      #Some failed so kick off minion restart and then delete their keys so that we can try again later
      if accepted_failed_minions:
        ret, err = restart_minions(client, accepted_failed_minions)
        if err:
          errors += err
        for m in accepted_failed_minions:
          r, err = delete_salt_key(m)
          if (not r) and err:
            errors += err
  
      if successful_gridcells:
        #Some succeeded so sync salt modules to those and regenerate the manifest and status.
        if print_progress:
          print "Syncing modules to GRIDCells"
        rc, err = sync_salt_modules(client, successful_gridcells)
        if err:
          raise Exception(err)
        if print_progress:
          print "Syncing modules to GRIDCells.. Done."
          print
  
        #print "Successfully added : %s"%successful_gridcells
        #print "Failed adding : %s"%failed_gridcells
  
        if print_progress:
          print "Regenerating manifest and status"
  
        #We now have a new minion so we need to update the manifest so that the appropriate status for the new minions will also get pulled in.
        rc, err = _regenerate_manifest_and_status(first_time)
        if not rc  :
          if err:
            errors += err
          else:
            errors += 'Error regenerating manifest and status'
        else:
          if print_progress:
            print "Regenerated manifest and status"
            try:
              if not first_time:
                for m in successful_gridcells:
                  rc = client.cmd(m,'file.copy',['/opt/integralstor/integralstor_gridcell/defaults/salt/minion','/etc/salt/minion',True])
                  rc = client.cmd(m,'cmd.run',['echo service salt-minion restart | at now + 1 minute'])    
            except Exception,e:  
              raise Exception(e)

      if errors:
        raise Exception(errors)
  except Exception, e:
    if errors:
      err = errors + ' ' + str(e)
    else:
      err = str(e)
    return (successful_gridcells, failed_gridcells), 'Error adding GRIDCells to the grid : %s'%err
  else:
    return (successful_gridcells, failed_gridcells), None

  
def main():
  #_regenerate_manifest_and_status(True)
  #add_nodes_to_grid("1.1.1.1",['a', 'b'], first_time = False, accessing_from = 'primary')
  pass

if __name__ == "__main__":
  main()

  """
      if wheel.call_func('key.accept', match=('%s'%m)):
	      time.sleep(20)
        command_to = 'salt %s saltutil.sync_all'%(m)
        ret, ret_code = command.execute_with_rc(command_to)
        #print ret, ret_code
        time.sleep(20)
        r = client.cmd(m, 'grains.item', ['ip_interfaces'], timeout=180)
        #print r
        if r:
          #print r[m]
          #print r[m]['ip_interfaces']
          #print r[m]['ip_interfaces']['bond0']
          if 'ip_interfaces' in r[m] and r[m]['ip_interfaces']['bond0']:
            ip = r[m]['ip_interfaces']['bond0'][0]
            print "Found Bond IP : %s"%ip
          else:
            print "Could not find the Bond IP"
        if ip:
          print "Adding %s to DNS"%m
          r1 = client.cmd('roles:primary', 'ddns.add_host', ['integralstor.lan', m, 86400, ip], expr_form='grain', timeout=180)
          print "Added %s to DNS"%m
          if not r1:
            errors = "Error adding the DNS information for GRIDCell %s"%m
            print "Error adding DNS information for GRIDCell %s"%m
          else:
            audit.audit("hardware_scan_node_added", "Added a new GRIDCell %s to the grid"%m,remote_addr )
            success.append(m)
        else:
            errors = "Error adding the DNS information for %s. No IP address information found."%m
            print "Error retrieving the IP from GRIDCell %s"%m
      else:
        failed.append(m)
    #print "Successfully added : %s"%success
    #print "Failed adding : %s"%failed
    print "Regenerating manifest and status"
    rc, err = _regenerate_manifest_and_status(first_time)
    print "Regenerated manifest and status"
    if not rc :
      if errors:
        errors += "Error regenerating the new configuration : "
      else:
        errors = "Error regenerating the new configuration : "
      errors += ",".join(command.get_output_list(ret))
      errors += ",".join(command.get_error_list(ret))
    #From regenerate_manifest_status
    manifest_command = "%s/generate_manifest.py %s"%(common_python_scripts_path, path)
    #print manifest_command
    (ret, rc), err = command.execute_with_rc(manifest_command)
    #print ret, rc
    if err:
      raise Exception(err)
    if rc != 0:
      errors = "Error regenerating the new manifest: "
      o, err = command.get_output_list(ret)
      if o:
        errors += ",".join(o)
      e, err = command.get_error_list(ret)
      if e:
        errors += ",".join(e)
      raise Exception(errors)
    status_command = "%s/generate_status.py %s"%(common_python_scripts_path, path)
    #print status_command
    (ret, rc), err = command.execute_with_rc(status_command)
    if err:
      raise Exception(err)
    #print ret, rc
    if rc != 0:
      errors = "Error regenerating the new status : "
      o, err = command.get_output_list(ret)
      if o:
        errors += ",".join(o)
      e, err = command.get_error_list(ret)
      if e:
        errors += ",".join(e)
      raise Exception(errors)

def set_pool_status(client, hostname_list, part_of_pool):
  #This is probably not needed anymore. Keeping just until we confirm.

  try :
    platform_root, err = common.get_platform_root()
    if err:
      raise Exception(err)
    if part_of_pool:
      cmd = 'touch %s/part_of_pool'%platform_root
    else:
      cmd = 'rm %s/part_of_pool'%platform_root

    r1 = client.cmd(hostname_list, 'cmd.run_all', [cmd], expr_form='list')
    #print r1
    if r1:
      for node, ret in r1.items():
        #print ret
        if ret["retcode"] not in [0, 1]:
          errors = "GRIDCell %s"%node
          raise Exception(errors)
  except Exception, e:
    return False, 'Error setting pool status : %s'%str(e)
  else:
    return True, None
  """
